{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cce82d3-7031-411a-8300-dba5d94dfc50",
   "metadata": {},
   "source": [
    "# Pipeline for generating snow depth maps from a source DEM and a reference DEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271825c1-e1c9-4e3a-8025-b1b18d09512d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import geedim as gd\n",
    "import ee\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import rioxarray as rxr\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import xdem\n",
    "import geoutils as gu\n",
    "import pyproj\n",
    "from scipy.stats import median_abs_deviation as MAD\n",
    "import math\n",
    "import pandas as pd\n",
    "import geoutils as gu\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1068a2c3-e25b-4077-bf82-11cb520a396e",
   "metadata": {},
   "source": [
    "## Define paths to DEMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55086c0-d6ea-4d68-b081-562b6829d6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define site name and source DEM date for convenience\n",
    "site_name = 'MCS'\n",
    "sourcedem_date = '20240420'\n",
    "data_dir = f'/Volumes/LaCie/raineyaberle/Research/PhD/SkySat-Stereo/study-sites/{site_name}'\n",
    "# data_dir = f'/Users/rdcrlrka/Research/PhD/SkySat-Stereo/study-sites/{site_name}/'\n",
    "refdem_fn = os.path.join(data_dir, 'refdem', 'MCS_REFDEM_WGS84.tif')\n",
    "sourcedem_fn = os.path.join(data_dir, sourcedem_date, f'{site_name}_{sourcedem_date}-1_DEM_masked-NMAD2m-refl10000.tif')\n",
    "\n",
    "# Define method for stable surfaces\n",
    "# Options = ['roads', 'Sentinel-2']\n",
    "#     If ss_method = 'roads', must have file in directory with the file name refdem_fn.replace('.tif', '_roads.shp') or refdem_fn.replace('.tif', '_roads.gpkg')\n",
    "#     If ss_method = 'Sentinel-2', will query GEE for closest Sentinel-2 date in time and create a mask based on an NDSI threshold of 0.4\n",
    "ss_method = 'roads' \n",
    "\n",
    "# Define path for output snow depth images\n",
    "out_dir = '/Volumes/LaCie/raineyaberle/Research/PhD/SkySat-Stereo/snow_depth_maps'\n",
    "# out_dir = f'/Users/rdcrlrka/Research/PhD/SkySat-Stereo/snow_depth_maps/'\n",
    "\n",
    "# Check that files exist\n",
    "if not os.path.exists(refdem_fn):\n",
    "    print('Reference DEM not found, check path to file before continuing.')\n",
    "if not os.path.exists(sourcedem_fn):\n",
    "    print('Source DEM not found, check path to file before continuing.')\n",
    "if not os.path.exists(out_dir):\n",
    "    os.mkdir(out_dir)\n",
    "    print('Created directory for output files:', out_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a456e06c-2168-409f-8457-4ffa6ab5d90f",
   "metadata": {},
   "source": [
    "## Construct stable surface mask for source DEM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4441197b-5721-49f8-82ef-f7424e3d9e66",
   "metadata": {},
   "source": [
    "### Sentinel-2 NDSI-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcd5af4-f1ce-4a1a-b0d6-8dab076dee7a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def convert_wgs_to_utm(lon: float, lat: float):\n",
    "    \"\"\"\n",
    "    Return best UTM EPSG code based on WGS84 lat and lon coordinate pair. \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    lon: float\n",
    "        longitude coordinate\n",
    "    lat: float\n",
    "        latitude coordinate\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    epsg_code: str\n",
    "        optimal UTM zone, e.g. \"EPSG:32606\"\n",
    "    \"\"\"\n",
    "    utm_band = str((math.floor((lon + 180) / 6) % 60) + 1)\n",
    "    if len(utm_band) == 1:\n",
    "        utm_band = '0' + utm_band\n",
    "    if lat >= 0:\n",
    "        epsg_code = 'EPSG:326' + utm_band\n",
    "        return epsg_code\n",
    "    epsg_code = 'EPSG:327' + utm_band\n",
    "    \n",
    "    return epsg_code\n",
    "\n",
    "def query_gee_for_image(dem_fn, dem_date, site_name, out_dir):\n",
    "    \"\"\"\n",
    "    Query Google Earth Engine for Landsat 8 and 9 surface reflectance (SR), Sentinel-2 top of atmosphere (TOA) or SR imagery.\n",
    "    Images captured within the hour will be mosaicked. For each image, run the classification and snowline detection workflow.\n",
    "\n",
    "    Parameters\n",
    "    __________\n",
    "    dem_bounds: list, numpy.array\n",
    "        bounds of the DEM used for querying and clipping imagery (format = [xmin, ymin, xmax, ymax])\n",
    "    date_date: str\n",
    "        date of the DEM (format = 'YYYYMMDD')\n",
    "    out_dir: str\n",
    "        path in directory where image will be saved\n",
    "\n",
    "    Returns\n",
    "    __________\n",
    "    im_xr: xarray.Dataset\n",
    "        resulting image\n",
    "    \"\"\"\n",
    "\n",
    "    # -----Authenticate and initialize GEE\n",
    "    try:\n",
    "        ee.Initialize()\n",
    "    except:\n",
    "        ee.Authenticate()\n",
    "        ee.Initialize()\n",
    "    \n",
    "    # -----Load DEM\n",
    "    dem = xr.open_dataset(dem_fn)\n",
    "    # Grab lat lon image bounds\n",
    "    dem_bounds = dem.rio.reproject('EPSG:4326').rio.bounds()\n",
    "    \n",
    "    # -----Estimate best UTM zone\n",
    "    centroid_lon = (dem_bounds[0] + dem_bounds[2]) / 2\n",
    "    centroid_lat = (dem_bounds[1] + dem_bounds[3]) / 2\n",
    "    crs = convert_wgs_to_utm(centroid_lon, centroid_lat)\n",
    "    print(f'Best UTM zone = {crs}')\n",
    "    \n",
    "    # -----Reformat image bounds for image querying and clipping\n",
    "    region = {'type': 'Polygon',\n",
    "              'coordinates': [[[dem_bounds[0], dem_bounds[1]],\n",
    "                              [dem_bounds[2], dem_bounds[1]],\n",
    "                              [dem_bounds[2], dem_bounds[3]],\n",
    "                              [dem_bounds[0], dem_bounds[3]],\n",
    "                              [dem_bounds[0], dem_bounds[1]]\n",
    "                             ]]\n",
    "             }\n",
    "\n",
    "    # -----Define the start and end dates for query (within two weeks of DEM date)\n",
    "    if '-' in dem_date:\n",
    "        dem_date = dem_date.replace('-','')\n",
    "    dem_dt = np.datetime64(f'{dem_date[0:4]}-{dem_date[4:6]}-{dem_date[6:8]}')\n",
    "    start_date = str(dem_dt - np.timedelta64(2, 'W'))\n",
    "    end_date = str(dem_dt + np.timedelta64(2, 'W'))\n",
    "\n",
    "    # -----Query GEE for imagery\n",
    "    im_col = gd.MaskedCollection.from_name('COPERNICUS/S2_SR_HARMONIZED').search(start_date=start_date,\n",
    "                                                                                 end_date=end_date,\n",
    "                                                                                 region=region,\n",
    "                                                                                 mask=True,\n",
    "                                                                                 fill_portion=70)\n",
    "    im_col_ids = np.array(im_col.ee_collection.aggregate_array('system:id').getInfo())\n",
    "    def sts_to_date(sts):\n",
    "        return ee.Date(sts).format('yyyy-MM-dd')\n",
    "    im_col_dts = np.array(im_col.ee_collection.aggregate_array('system:time_start').map(sts_to_date).getInfo(), dtype='datetime64[D]')\n",
    "\n",
    "    # -----Download the closest image in time\n",
    "    # Identify ID of the closest image in time\n",
    "    dt_diffs = dem_dt - im_col_dts\n",
    "    Iclosest = np.ravel(np.argwhere(dt_diffs==np.min(dt_diffs)))[0]\n",
    "    im_id = im_col_ids[Iclosest] \n",
    "    im_dt = im_col_dts[Iclosest] \n",
    "    print(f'Closest image date = {im_dt}')\n",
    "    # Create new masked image from ID\n",
    "    im = gd.MaskedImage.from_id(im_id, mask=True, region=region)\n",
    "    # Download to file\n",
    "    out_fn = os.path.join(os.path.dirname(out_dir), f\"{site_name}_{str(im_dt).replace('-','')}_S2_SR_HARMONIZED.tif\")\n",
    "    refl_bands = im.refl_bands\n",
    "    if not os.path.exists(out_fn):\n",
    "        im.download(out_fn, region=region, scale=10, crs=crs, bands=refl_bands, dtype='int16')\n",
    "        print('Sentinel-2 image saved to file:', out_fn)\n",
    "    else:\n",
    "        print('Sentinel-2 image file already exists in directory, loading...')\n",
    "\n",
    "    # -----Open image and restructure data variables\n",
    "    im_xr = xr.open_dataset(out_fn)\n",
    "    band_data = im_xr['band_data']\n",
    "    im_xr_adj = xr.Dataset()\n",
    "    for i, band_name in enumerate(refl_bands):\n",
    "        im_xr_adj[band_name] = band_data.isel(band=i)\n",
    "    im_xr_adj.attrs = im_xr.attrs\n",
    "    for coord in im_xr.coords:\n",
    "        im_xr_adj[coord] = im_xr[coord]\n",
    "    im_xr_adj = im_xr_adj / 1e4 # account for reflectance scalar\n",
    "    \n",
    "    return im_xr_adj, crs\n",
    "\n",
    "def create_stable_surface_mask(im_xr, dem_date, out_fn, crs, plot=True):\n",
    "    \"\"\"\n",
    "    Create stable surface mask by applying an NDSI threshold of 0.35 to the input Sentinel-2 SR image\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    im_xr: xarray.Dataset\n",
    "        input Sentinel-2 SR image\n",
    "    dem_date: str\n",
    "        observation date of DEM\n",
    "    out_fn: str\n",
    "        file name of output stable surfaces file\n",
    "    crs: str\n",
    "        coordinate reference system of output file (e.g., \"EPSG:4326\")\n",
    "    plot: bool\n",
    "        whether to plot results\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    stable_surfaces: xarray.DataArray\n",
    "        resulting stable surfaces mask\n",
    "    \n",
    "    \"\"\"\n",
    "    # Add NDSI band\n",
    "    im_xr['NDSI'] = (im_xr['B3'] - im_xr['B11']) / (im_xr['B3'] + im_xr['B11'])\n",
    "    \n",
    "    # Threshold\n",
    "    ss_xr = xr.where(im_xr['NDSI'] <= 0.4, 1, 0)\n",
    "\n",
    "    # Calculate statistics\n",
    "    num_pixels = len(np.ravel(ss_xr.data))\n",
    "    num_pixels_stable = len(np.argwhere(np.ravel(ss_xr.data)==1))\n",
    "    res_m2 = (ss_xr.x.data[1] - ss_xr.x.data[0]) **2\n",
    "    perc_stable = num_pixels_stable / num_pixels * 100\n",
    "    area_stable_km2 = num_pixels_stable * res_m2 / 1e6\n",
    "    print(f'Stable surfaces = {np.round(perc_stable,2)} % of image, {np.round(area_stable_km2, 2)} km2')\n",
    "\n",
    "    # Write CRS to image\n",
    "    ss_xr = ss_xr.rio.write_crs(crs)\n",
    "    \n",
    "    # Save to file\n",
    "    ss_xr.rio.to_raster(out_fn)\n",
    "    print('Stable surfaces mask saved to file:', out_fn)\n",
    "\n",
    "    ss_xr = rxr.open_rasterio(out_fn)\n",
    "    \n",
    "    # Plot\n",
    "    if plot:\n",
    "        fig, ax = plt.subplots(1, 3, figsize=(12,6))\n",
    "        ax[0].imshow(np.dstack([im_xr.B4.data, im_xr.B3.data, im_xr.B2.data]),\n",
    "                     extent=(np.min(im_xr.x.data), np.max(im_xr.x.data), np.min(im_xr.y.data), np.max(im_xr.y.data)))\n",
    "        ax[0].set_title('Raw image')\n",
    "        ax[1].imshow(im_xr.NDSI.data, clim=(-1,1), cmap='Blues',\n",
    "                     extent=(np.min(im_xr.x.data), np.max(im_xr.x.data), np.min(im_xr.y.data), np.max(im_xr.y.data)))\n",
    "        ax[1].set_title('NDSI')\n",
    "        ax[2].imshow(ss_xr.data[0], clim=(0,1), cmap='Greys',\n",
    "                     extent=(np.min(ss_xr.x.data), np.max(ss_xr.x.data), np.min(ss_xr.y.data), np.max(ss_xr.y.data)))\n",
    "        ax[2].set_title('Stable surfaces')\n",
    "        plt.show()\n",
    "        # save figure\n",
    "        fig_fn = os.path.splitext(out_fn)[0] + '.png'\n",
    "        fig.savefig(fig_fn, dpi=250, bbox_inches='tight')\n",
    "        print('Figure saved to file:', fig_fn)\n",
    "\n",
    "    return ss_xr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262de4f9-3db2-425c-98cb-796906c3140f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define stable surfaces mask file name based on method\n",
    "if ss_method == 'Sentinel-2':\n",
    "    # Check if stable surfaces mask already exists in file\n",
    "    ss_fn = os.path.join(out_dir, os.path.splitext(os.path.basename(sourcedem_fn))[0] + '_stable_surfaces_mask.tif')\n",
    "    if os.path.exists(ss_fn):\n",
    "        print('Stable surfaces mask already exists for DEM')\n",
    "        ss_xr = rxr.open_rasterio(ss_fn)\n",
    "        ss_xr.plot(cmap='Greys', vmin=0, vmax=1)\n",
    "        plt.show()\n",
    "    else:\n",
    "        # Query GEE for closest Sentinel-2 image in time\n",
    "        im_xr, crs = query_gee_for_image(sourcedem_fn, sourcedem_date, site_name, out_dir)\n",
    "        # Create stable surfaces mask\n",
    "        ss_xr = create_stable_surface_mask(im_xr, sourcedem_date, ss_fn, crs=crs, plot=True)\n",
    "\n",
    "elif ss_method == 'roads':\n",
    "    ss_fn = refdem_fn.replace('.tif', '_roads.shp')\n",
    "    if os.path.exists(ss_fn):\n",
    "        ss_gpd = gpd.read_file(ss_fn)\n",
    "        ss_gpd.plot()\n",
    "    else:\n",
    "        print('Roads vector does not exist in file, please create or change \"ss_method\" to \"Sentinel-2\"')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee833b22-42e5-4a35-bd41-b10d06317ebc",
   "metadata": {},
   "source": [
    "## Define functions for coregistration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496688a1-fc2c-4c41-9103-5402092d8fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_coreg_object(coreg_name):\n",
    "    if type(coreg_name) == list:\n",
    "        try:\n",
    "            coreg_class = getattr(xdem.coreg.CoregPipeline, coreg_name)\n",
    "            return coreg_class()\n",
    "        except AttributeError:\n",
    "            raise ValueError(f\"Coregistration method '{coreg_name}' not found.\")\n",
    "    elif type(coreg_name) == str:\n",
    "        try:\n",
    "            coreg_class = getattr(xdem.coreg, coreg_name)\n",
    "            return coreg_class()\n",
    "        except AttributeError:\n",
    "            raise ValueError(f\"Coregistration method '{coreg_name}' not found.\")\n",
    "    else:\n",
    "        print('coreg_method format not recognized, exiting...')\n",
    "        return None\n",
    "\n",
    "\n",
    "def differences_vs_slope_aspect(dem, diffs):\n",
    "    # Calculate slope and aspect from DEM\n",
    "    slope = xdem.terrain.slope(dem)\n",
    "    aspect = xdem.terrain.aspect(dem)\n",
    "    \n",
    "    # Compile differences, slopes, and aspects in a dataframe\n",
    "    df = pd.DataFrame({'diff': np.ravel(diffs.data),\n",
    "                       'elev': np.ravel(dem.data),\n",
    "                       'slope': np.ravel(slope.data),\n",
    "                       'aspect': np.ravel(aspect.data)})\n",
    "    df.dropna(inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Create bins for elev, slope, and aspect\n",
    "    df['elev_bin'] = pd.cut(df['elev'], bins=10)\n",
    "    df['slope_bin'] = pd.cut(df['slope'], bins=np.arange(0, 41, step=5))\n",
    "    df['aspect_bin'] = pd.cut(df['aspect'], bins=np.arange(0, 361, step=45))\n",
    "\n",
    "    # Plot\n",
    "    fig2, ax = plt.subplots(3, 1, figsize=(8,16))\n",
    "    # elev\n",
    "    df.boxplot(column='diff', by='elev_bin', showfliers=False, ax=ax[0])\n",
    "    ax[0].set_title('')\n",
    "    ax[0].set_xlabel('Elevation range [m]')\n",
    "    # slope\n",
    "    df.boxplot(column='diff', by='slope_bin', showfliers=False, ax=ax[1])\n",
    "    ax[1].set_title('')\n",
    "    ax[1].set_xlabel('Slope range [degrees]')\n",
    "    # aspect\n",
    "    df.boxplot(column='diff', by='aspect_bin', showfliers=False, ax=ax[2])\n",
    "    ax[2].set_title('')\n",
    "    ax[2].set_xlabel('Aspect range [degrees from North]')\n",
    "    for axis in ax:\n",
    "        axis.set_ylabel('Differences [m]')\n",
    "    fig2.tight_layout()\n",
    "    \n",
    "    return fig2\n",
    "\n",
    "def calculate_stable_surface_stats(diff_dem, ss_mask):\n",
    "    diff_dem_ss = np.ma.masked_where(np.logical_or(diff_dem.data.mask, ss_mask.data), diff_dem.data)\n",
    "    diff_dem_ss_median = np.nanmedian(gu.raster.get_array_and_mask(diff_dem_ss)[0])\n",
    "    diff_dem_ss_nmad = xdem.spatialstats.nmad(diff_dem)\n",
    "    return diff_dem_ss, diff_dem_ss_median, diff_dem_ss_nmad\n",
    "\n",
    "def plot_coreg_dh_results(dh_before, dh_before_ss, dh_before_ss_med, dh_before_ss_nmad,\n",
    "                          dh_after, dh_after_ss, dh_after_ss_med, dh_after_ss_nmad,\n",
    "                          dh_after_ss_adj, dh_after_ss_adj_ss, dh_after_ss_adj_ss_med, dh_after_ss_adj_ss_nmad,\n",
    "                          vmin=-10, vmax=10):\n",
    "    fig, ax = plt.subplots(3, 2, figsize=(12,16))\n",
    "    dhs = [dh_before, dh_after, dh_after_ss_adj]\n",
    "    titles = ['Difference before coreg.', 'Difference after coreg.', 'Difference after coreg. - median SS diff.']\n",
    "    dhs_ss = [dh_before_ss, dh_after_ss, dh_after_ss_adj_ss]\n",
    "    ss_meds = [dh_before_ss_med, dh_after_ss_med, dh_after_ss_adj_ss_med]\n",
    "    ss_nmads = [dh_before_ss_nmad, dh_after_ss_nmad, dh_after_ss_adj_ss_nmad]\n",
    "    for i in range(len(dhs)):\n",
    "        # plot dh\n",
    "        dhs[i].plot(cmap=\"coolwarm_r\", ax=ax[i,0], vmin=vmin, vmax=vmax)\n",
    "        ax[i,0].set_title(f'{titles[i]} \\nSS median = {np.round(ss_meds[i], 3)}, SS NMAD = {np.round(ss_nmads[i], 3)}')\n",
    "        # Adjust map units to km\n",
    "        ax[i,0].set_xticks(ax[i,0].get_xticks())\n",
    "        ax[i,0].set_xticklabels(np.divide(ax[i,0].get_xticks(), 1e3).astype(str))\n",
    "        ax[i,0].set_yticks(ax[i,0].get_yticks())\n",
    "        ax[i,0].set_yticklabels(np.divide(ax[i,0].get_yticks(), 1e3).astype(str))\n",
    "        ax[i,0].set_xlabel('Easting [km]')\n",
    "        ax[i,0].set_ylabel('Northing [km]')\n",
    "        # plot histograms\n",
    "        ax[i,1].hist(np.ravel(dhs[i].data), bins=50, color='grey', alpha=0.8, label='All surfaces')\n",
    "        ax[i,1].hist(np.ravel(dhs_ss[i]), bins=50, color='m', alpha=0.8, label='Stable surfaces')\n",
    "        ax[i,1].legend(loc='upper right')\n",
    "        ax[i,1].set_xlabel('Differences [m]')\n",
    "        ax[i,1].set_ylabel('Counts')\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    return fig\n",
    "                                           \n",
    "def coregister_difference_dems(ref_dem_fn=None, source_dem_fn=None, ss_mask_fn=None, out_dir=None, \n",
    "                               coreg_method='NuthKaab', coreg_stable_only=False, ss_method='Sentinel-2'):\n",
    "    # -----Define output file names\n",
    "    if coreg_stable_only:\n",
    "        coreg_suffix = 'ss-only'\n",
    "    else:\n",
    "        coreg_suffix = 'all-surfaces'\n",
    "    if ss_method == 'Sentinel-2':\n",
    "        ss_suffix = 'ss-S2'\n",
    "    elif ss_method == 'roads':\n",
    "        ss_suffix = 'ss-roads'\n",
    "    out_fn = os.path.join(out_dir, os.path.basename(source_dem_fn).replace('.tif', f'_{ss_suffix}_{coreg_method}-{coreg_suffix}_differences.tif'))\n",
    "    fig1_fn = out_fn.replace('.tif', '.png')\n",
    "    fig2_fn = out_fn.replace('.tif', '_boxplots.png')\n",
    "    \n",
    "    # -----Check if output DEM already exists in file\n",
    "    if os.path.exists(out_fn):\n",
    "        print('Output differences DEM already exists file, loading...')\n",
    "        diff_after_ss_adj = xdem.DEM(out_fn, load_data=True)\n",
    "\n",
    "    else:\n",
    "    \n",
    "        # Load DEMs\n",
    "        ref_dem = xdem.DEM(gu.Raster(ref_dem_fn, load_data=True, bands=1))\n",
    "        tba_dem = xdem.DEM(gu.Raster(source_dem_fn, load_data=True, bands=1))\n",
    "\n",
    "        # Load stable surfaces mask\n",
    "        if os.path.splitext(ss_fn)[1] == '.tif':\n",
    "            ss_mask = gu.Raster(ss_fn, load_data=True)\n",
    "        elif (os.path.splitext(ss_fn)[1] == '.shp') or (os.path.splitext(ss_fn)[1] == '.gpkg'):\n",
    "            ss_vector = gu.Vector(ss_fn)\n",
    "            ss_mask = ss_vector.rasterize(ref_dem) # rasterize vector\n",
    "        ss_mask = (ss_mask == 0)  # Convert to boolean mask\n",
    "\n",
    "        # Reproject source DEM and stable surfaces mask to reference DEM grid\n",
    "        tba_dem = tba_dem.reproject(ref_dem)\n",
    "        ss_mask = ss_mask.reproject(ref_dem)\n",
    "        \n",
    "        # Set up the coregistration object\n",
    "        coreg_obj = create_coreg_object(coreg_method)\n",
    "    \n",
    "        # Calculate differences before coregistration\n",
    "        print('Calculating differences before coregistration...')\n",
    "        diff_before = tba_dem - ref_dem\n",
    "        # Calculate stable surface stats\n",
    "        diff_before_ss, diff_before_ss_median, diff_before_ss_nmad = calculate_stable_surface_stats(diff_before, ss_mask)\n",
    "    \n",
    "        # Fit the coregistration object\n",
    "        print('Coregistering source DEM to reference DEM...')\n",
    "        if coreg_stable_only:\n",
    "            coreg_obj.fit(ref_dem, tba_dem, ss_mask)   \n",
    "        else:\n",
    "            coreg_obj.fit(ref_dem, tba_dem)\n",
    "        print(coreg_obj.meta)\n",
    "        \n",
    "        # Apply the coregistration object\n",
    "        aligned_dem = coreg_obj.apply(tba_dem)\n",
    "        \n",
    "        # Calculate differences after coregistration\n",
    "        print('Calculating differences after coregistration...')\n",
    "        diff_after = aligned_dem - ref_dem\n",
    "        # Stable surface stats\n",
    "        diff_after_ss, diff_after_ss_median, diff_after_ss_nmad = calculate_stable_surface_stats(diff_after, ss_mask)\n",
    "\n",
    "        # Subtract the median difference over stable surfaces\n",
    "        diff_after_ss_adj = diff_after - diff_after_ss_median\n",
    "        # Stable surfaces stats\n",
    "        diff_after_ss_adj_ss, diff_after_ss_adj_ss_median, diff_after_ss_adj_ss_nmad = calculate_stable_surface_stats(diff_after_ss_adj, ss_mask)\n",
    "\n",
    "        # Save output to file\n",
    "        diff_after_ss_adj.save(out_fn)\n",
    "        print('dDEM saved to file:', out_fn)\n",
    "    \n",
    "    # Plot results\n",
    "    print('Plotting results...')\n",
    "    if os.path.exists(fig1_fn):\n",
    "        print('Figure 1 already exists in file, skipping')\n",
    "    else:\n",
    "        fig1 = plot_coreg_dh_results(diff_before, diff_before_ss, diff_before_ss_median, diff_before_ss_nmad,\n",
    "                                     diff_after, diff_after_ss, diff_after_ss_median, diff_after_ss_nmad,\n",
    "                                     diff_after_ss_adj, diff_after_ss_adj_ss, diff_after_ss_adj_ss_median, diff_after_ss_adj_ss_nmad,\n",
    "                                     vmin=-10, vmax=10)\n",
    "        # Save to file\n",
    "        fig1.savefig(fig1_fn, dpi=300, bbox_inches='tight')\n",
    "        print('Figure 1 saved to file:', fig1_fn)\n",
    "\n",
    "    # Calculate differences as a function of slope and aspect\n",
    "    if os.path.exists(fig2_fn):\n",
    "        print('Figure 2 already exists in file, skipping')\n",
    "    else:\n",
    "        print('Calculating differences as a function of slope and aspect...')\n",
    "        fig2 = differences_vs_slope_aspect(ref_dem, diff_after_ss_adj)\n",
    "        # Save to file\n",
    "        fig2.savefig(fig2_fn, dpi=300, bbox_inches='tight')\n",
    "        print('Figure 2 saved to file:', fig2_fn)\n",
    "\n",
    "    return diff_after_ss_adj\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cff225a-28f3-4bb7-bea6-59716c1e3238",
   "metadata": {},
   "source": [
    "### Nuth and Kaab - coregister all surfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bb9907-8ce1-4f70-ad12-6438fd76c1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_after = coregister_difference_dems(ref_dem_fn=refdem_fn, \n",
    "                                        source_dem_fn=sourcedem_fn, \n",
    "                                        ss_mask_fn=ss_fn, \n",
    "                                        out_dir=out_dir,\n",
    "                                        coreg_method='NuthKaab', \n",
    "                                        coreg_stable_only=False,\n",
    "                                        ss_method=ss_method)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4bec5e-ef1d-41eb-857c-738db6844962",
   "metadata": {},
   "source": [
    "### Nuth and Kaab - coregister stable surfaces only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c09cae6-e7e4-405c-b8cd-33b704d6a59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_after = coregister_difference_dems(ref_dem_fn=refdem_fn, \n",
    "                                        source_dem_fn=sourcedem_fn, \n",
    "                                        ss_mask_fn=ss_fn, \n",
    "                                        out_dir=out_dir,\n",
    "                                        coreg_method='NuthKaab', \n",
    "                                        coreg_stable_only=True,\n",
    "                                        ss_method=ss_method)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5949d9ee-6bcb-494d-a0a2-1a02507ebe33",
   "metadata": {},
   "source": [
    "### Gradient Descending - coregister all surfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261ce619-6f8d-449e-b798-29a96a3a26e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_after = coregister_difference_dems(ref_dem_fn=refdem_fn, \n",
    "                                        source_dem_fn=sourcedem_fn, \n",
    "                                        ss_mask_fn=ss_fn, \n",
    "                                        out_dir=out_dir,\n",
    "                                        coreg_method='GradientDescending', \n",
    "                                        coreg_stable_only=False,\n",
    "                                        ss_method=ss_method)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bc0a26-00dc-4e46-bcb9-b0525ebd99bf",
   "metadata": {},
   "source": [
    "### Gradient Descending - coregister stable surfaces only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea589bd-c28d-4d2d-ac08-f7faccbce73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_after = coregister_difference_dems(ref_dem_fn=refdem_fn, \n",
    "                                        source_dem_fn=sourcedem_fn, \n",
    "                                        ss_mask_fn=ss_fn, \n",
    "                                        out_dir=out_dir\n",
    "                                        coreg_method='GradientDescending', \n",
    "                                        coreg_stable_only=True,\n",
    "                                        ss_method=ss_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b668eb5a-38b7-4e56-b679-87bfeefb87f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snow-dems",
   "language": "python",
   "name": "snow-dems"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
