{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cce82d3-7031-411a-8300-dba5d94dfc50",
   "metadata": {},
   "source": [
    "# Pipeline for generating snow depth maps from a source DEM and a reference DEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271825c1-e1c9-4e3a-8025-b1b18d09512d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import geedim as gd\n",
    "import ee\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import rioxarray as rxr\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import xdem\n",
    "import geoutils as gu\n",
    "import pyproj\n",
    "from scipy.stats import median_abs_deviation as MAD\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1068a2c3-e25b-4077-bf82-11cb520a396e",
   "metadata": {},
   "source": [
    "## Define paths to DEMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55086c0-d6ea-4d68-b081-562b6829d6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define site name and source DEM date for convenience\n",
    "site_name = 'JacksonCreek'\n",
    "sourcedem_date = '20240420'\n",
    "data_path = f'/Volumes/LaCie/raineyaberle/Research/PhD/SkySat-Stereo/study-sites/{site_name}/'\n",
    "# refdem_fn = os.path.join(data_path, 'refdem', 'Banner_NASADEM_clip_buffer_2km_EPSG32611+5773.tif')\n",
    "sourcedem_fn = glob.glob(os.path.join(data_path, sourcedem_date, '*DEM.tif'))[0]\n",
    "\n",
    "# Define path for output snow depth images\n",
    "out_dir = f'/Volumes/LaCie/raineyaberle/Research/PhD/SkySat-Stereo/snow_depth_maps/'\n",
    "\n",
    "# Check that files exist\n",
    "# if not os.path.exists(refdem_fn):\n",
    "#     print('Reference DEM not found, check path to file before continuing.')\n",
    "if not os.path.exists(sourcedem_fn):\n",
    "    print('Source DEM not found, check path to file before continuing.')\n",
    "if not os.path.exists(out_dir):\n",
    "    os.mkdir(out_dir)\n",
    "    print('Created directory for output files:', out_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a456e06c-2168-409f-8457-4ffa6ab5d90f",
   "metadata": {},
   "source": [
    "## Construct stable surface mask for source DEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426f2871-c3ee-4fca-a158-2710a939ce53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate and initialize GEE\n",
    "try:\n",
    "    ee.Initialize()\n",
    "except:\n",
    "    ee.Authenticate()\n",
    "    ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcd5af4-f1ce-4a1a-b0d6-8dab076dee7a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def convert_wgs_to_utm(lon: float, lat: float):\n",
    "    \"\"\"\n",
    "    Return best UTM EPSG code based on WGS84 lat and lon coordinate pair. \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    lon: float\n",
    "        longitude coordinate\n",
    "    lat: float\n",
    "        latitude coordinate\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    epsg_code: str\n",
    "        optimal UTM zone, e.g. \"EPSG:32606\"\n",
    "    \"\"\"\n",
    "    utm_band = str((math.floor((lon + 180) / 6) % 60) + 1)\n",
    "    if len(utm_band) == 1:\n",
    "        utm_band = '0' + utm_band\n",
    "    if lat >= 0:\n",
    "        epsg_code = 'EPSG:326' + utm_band\n",
    "        return epsg_code\n",
    "    epsg_code = 'EPSG:327' + utm_band\n",
    "    \n",
    "    return epsg_code\n",
    "\n",
    "def query_gee_for_image(dem_fn, dem_date, site_name, out_dir):\n",
    "    \"\"\"\n",
    "    Query Google Earth Engine for Landsat 8 and 9 surface reflectance (SR), Sentinel-2 top of atmosphere (TOA) or SR imagery.\n",
    "    Images captured within the hour will be mosaicked. For each image, run the classification and snowline detection workflow.\n",
    "\n",
    "    Parameters\n",
    "    __________\n",
    "    dem_bounds: list, numpy.array\n",
    "        bounds of the DEM used for querying and clipping imagery (format = [xmin, ymin, xmax, ymax])\n",
    "    date_date: str\n",
    "        date of the DEM (format = 'YYYYMMDD')\n",
    "    out_dir: str\n",
    "        path in directory where image will be saved\n",
    "\n",
    "    Returns\n",
    "    __________\n",
    "    im_xr: xarray.Dataset\n",
    "        resulting image\n",
    "    \"\"\"\n",
    "\n",
    "    # -----Load DEM\n",
    "    dem = xr.open_dataset(dem_fn)\n",
    "    # Grab lat lon image bounds\n",
    "    dem_bounds = dem.rio.reproject('EPSG:4326').rio.bounds()\n",
    "    \n",
    "    # -----Estimate best UTM zone\n",
    "    centroid_lon = (dem_bounds[0] + dem_bounds[2]) / 2\n",
    "    centroid_lat = (dem_bounds[1] + dem_bounds[3]) / 2\n",
    "    crs = convert_wgs_to_utm(centroid_lon, centroid_lat)\n",
    "    print(f'Best UTM zone = {crs}')\n",
    "    \n",
    "    # -----Reformat image bounds for image querying and clipping\n",
    "    region = {'type': 'Polygon',\n",
    "              'coordinates': [[[dem_bounds[0], dem_bounds[1]],\n",
    "                              [dem_bounds[2], dem_bounds[1]],\n",
    "                              [dem_bounds[2], dem_bounds[3]],\n",
    "                              [dem_bounds[0], dem_bounds[3]],\n",
    "                              [dem_bounds[0], dem_bounds[1]]\n",
    "                             ]]\n",
    "             }\n",
    "\n",
    "    # -----Define the start and end dates for query (within two weeks of DEM date)\n",
    "    if '-' in dem_date:\n",
    "        dem_date = dem_date.replace('-','')\n",
    "    dem_dt = np.datetime64(f'{dem_date[0:4]}-{dem_date[4:6]}-{dem_date[6:8]}')\n",
    "    start_date = str(dem_dt - np.timedelta64(2, 'W'))\n",
    "    end_date = str(dem_dt + np.timedelta64(2, 'W'))\n",
    "\n",
    "    # -----Query GEE for imagery\n",
    "    im_col = gd.MaskedCollection.from_name('COPERNICUS/S2_SR_HARMONIZED').search(start_date=start_date,\n",
    "                                                                                 end_date=end_date,\n",
    "                                                                                 region=region,\n",
    "                                                                                 mask=True,\n",
    "                                                                                 fill_portion=70)\n",
    "    im_col_ids = np.array(im_col.ee_collection.aggregate_array('system:id').getInfo())\n",
    "    def sts_to_date(sts):\n",
    "        return ee.Date(sts).format('yyyy-MM-dd')\n",
    "    im_col_dts = np.array(im_col.ee_collection.aggregate_array('system:time_start').map(sts_to_date).getInfo(), dtype='datetime64[D]')\n",
    "\n",
    "    # -----Download the closest image in time\n",
    "    # Identify ID of the closest image in time\n",
    "    dt_diffs = dem_dt - im_col_dts\n",
    "    Iclosest = np.ravel(np.argwhere(dt_diffs==np.min(dt_diffs)))[0]\n",
    "    im_id = im_col_ids[Iclosest] \n",
    "    im_dt = im_col_dts[Iclosest] \n",
    "    print(f'Closest image date = {im_dt}')\n",
    "    # Create new masked image from ID\n",
    "    im = gd.MaskedImage.from_id(im_id, mask=True, region=region)\n",
    "    # Download to file\n",
    "    out_fn = os.path.join(os.path.dirname(out_dir), f\"{site_name}_{str(im_dt).replace('-','')}_S2_SR_HARMONIZED.tif\")\n",
    "    refl_bands = im.refl_bands\n",
    "    if not os.path.exists(out_fn):\n",
    "        im.download(out_fn, region=region, scale=10, crs=crs, bands=refl_bands, dtype='int16')\n",
    "        print('Sentinel-2 image saved to file:', out_fn)\n",
    "    else:\n",
    "        print('Sentinel-2 image file already exists in directory, loading...')\n",
    "\n",
    "    # -----Open image and restructure data variables\n",
    "    im_xr = xr.open_dataset(out_fn)\n",
    "    band_data = im_xr['band_data']\n",
    "    im_xr_adj = xr.Dataset()\n",
    "    for i, band_name in enumerate(refl_bands):\n",
    "        im_xr_adj[band_name] = band_data.isel(band=i)\n",
    "    im_xr_adj.attrs = im_xr.attrs\n",
    "    for coord in im_xr.coords:\n",
    "        im_xr_adj[coord] = im_xr[coord]\n",
    "    im_xr_adj = im_xr_adj / 1e4 # account for reflectance scalar\n",
    "    \n",
    "    return im_xr_adj, crs\n",
    "\n",
    "def create_stable_surface_mask(im_xr, dem_date, out_fn, crs, plot=True):\n",
    "    \"\"\"\n",
    "    Create stable surface mask by applying an NDSI threshold of 0.35 to the input Sentinel-2 SR image\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    im_xr: xarray.Dataset\n",
    "        input Sentinel-2 SR image\n",
    "    dem_date: str\n",
    "        observation date of DEM\n",
    "    out_fn: str\n",
    "        file name of output stable surfaces file\n",
    "    crs: str\n",
    "        coordinate reference system of output file (e.g., \"EPSG:4326\")\n",
    "    plot: bool\n",
    "        whether to plot results\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    stable_surfaces: xarray.DataArray\n",
    "        resulting stable surfaces mask\n",
    "    \n",
    "    \"\"\"\n",
    "    # Add NDSI band\n",
    "    im_xr['NDSI'] = (im_xr['B3'] - im_xr['B11']) / (im_xr['B3'] + im_xr['B11'])\n",
    "    \n",
    "    # Threshold\n",
    "    ss_xr = xr.where(im_xr['NDSI'] <= 0.4, 1, 0)\n",
    "\n",
    "    # Calculate statistics\n",
    "    num_pixels = len(np.ravel(ss_xr.data))\n",
    "    num_pixels_stable = len(np.argwhere(np.ravel(ss_xr.data)==1))\n",
    "    res_m2 = (ss_xr.x.data[1] - ss_xr.x.data[0]) **2\n",
    "    perc_stable = num_pixels_stable / num_pixels * 100\n",
    "    area_stable_km2 = num_pixels_stable * res_m2 / 1e6\n",
    "    print(f'Stable surfaces = {np.round(perc_stable,2)} % of image, {np.round(area_stable_m2, 2)} km2')\n",
    "\n",
    "    # Write CRS to image\n",
    "    ss_xr = ss_xr.rio.write_crs(crs)\n",
    "    \n",
    "    # Save to file\n",
    "    ss_xr.rio.to_raster(out_fn)\n",
    "    print('Stable surfaces mask saved to file:', out_fn)\n",
    "    \n",
    "    # Plot\n",
    "    if plot:\n",
    "        fig, ax = plt.subplots(1, 3, figsize=(12,6))\n",
    "        ax[0].imshow(np.dstack([im_xr.B4.data, im_xr.B3.data, im_xr.B2.data]),\n",
    "                     extent=(np.min(im_xr.x.data), np.max(im_xr.x.data), np.min(im_xr.y.data), np.max(im_xr.y.data)))\n",
    "        ax[0].set_title('Raw image')\n",
    "        ax[1].imshow(im_xr.NDSI.data, clim=(-1,1), cmap='Blues',\n",
    "                     extent=(np.min(im_xr.x.data), np.max(im_xr.x.data), np.min(im_xr.y.data), np.max(im_xr.y.data)))\n",
    "        ax[1].set_title('NDSI')\n",
    "        ax[2].imshow(ss_xr.data, clim=(0,1), cmap='Greys',\n",
    "                     extent=(np.min(ss_xr.x.data), np.max(ss_xr.x.data), np.min(ss_xr.y.data), np.max(ss_xr.y.data)))\n",
    "        ax[2].set_title('Stable surfaces')\n",
    "        plt.show()\n",
    "        # save figure\n",
    "        fig_fn = os.path.splitext(out_fn)[0] + '.png'\n",
    "        fig.savefig(fig_fn, dpi=250, bbox_inches='tight')\n",
    "        print('Figure saved to file:', fig_fn)\n",
    "\n",
    "    return ss_xr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262de4f9-3db2-425c-98cb-796906c3140f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if stable surfaces mask already exists in file\n",
    "ss_fn = os.path.join(out_dir, os.path.splitext(os.path.basename(sourcedem_fn))[0] + '_stable_surfaces_mask.tif')\n",
    "if os.path.exists(ss_fn):\n",
    "    print('Stable surfaces mask already exists for DEM, skipping...')\n",
    "\n",
    "else:\n",
    "    \n",
    "    # Query GEE for closest Sentinel-2 image in time\n",
    "    im_xr, crs = query_gee_for_image(sourcedem_fn, sourcedem_date, site_name, out_dir)\n",
    "    \n",
    "    # Create stable surfaces mask\n",
    "    ss_xr = create_stable_surface_mask(im_xr, sourcedem_date, ss_fn, crs=crs, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc19a93-278d-426c-896e-aa21f935bebf",
   "metadata": {},
   "source": [
    "## Coregister source DEM to reference DEM grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5537bd-2783-4634-bf4e-df97ddf9cbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coregister(coreg_obj, ref_dem, source_dem, ss_mask):\n",
    "    # Set up figure\n",
    "    fig, ax = plt.subplots(2, 3, figsize=(12,8))\n",
    "    ax = ax.flatten()\n",
    "    \n",
    "    # Calculate difference before registration\n",
    "    diff_before = source_dem - ref_dem\n",
    "    diff_before.set_nodata(0)\n",
    "    # calculate differences over stable surfaces\n",
    "    ss_mask = ss_mask.reproject(diff_before)\n",
    "    diff_before_ss = diff_before[ss_mask]\n",
    "    med_before_ss, nmad_before_ss = np.median(diff_before_ss), xdem.spatialstats.nmad(diff_before_ss)\n",
    "    # plot\n",
    "    diff_before.plot(cmap=\"coolwarm_r\", ax=ax[0])\n",
    "    ax[0].set_title(f'Difference before coreg. \\nSS median = {np.round(med_before_ss,3)}, SS NMAD = {np.round(nmad_before_ss,3)}')\n",
    "        \n",
    "    # Apply coregistration\n",
    "    coreg_obj.fit(ref_dem, source_dem)\n",
    "    aligned_dem = coreg_obj.apply(source_dem)\n",
    "    diff_after = aligned_dem - ref_dem\n",
    "    # calculate differences over stable surfaces\n",
    "    ss_mask = ss_mask.reproject(diff_after)\n",
    "    diff_after_ss = diff_after[ss_mask]\n",
    "    med_after_ss, nmad_after_ss = np.median(diff_after_ss), xdem.spatialstats.nmad(diff_after_ss)\n",
    "    # plot\n",
    "    diff_after.plot(cmap=\"coolwarm_r\", vmin=vmin, vmax=vmax, ax=ax[1])\n",
    "    ax[1].set_title(f'Difference after coreg. \\nSS median = {np.round(med_after_ss,3)}, SS NMAD = {np.round(nmad_after_ss,3)}')\n",
    "    ax[1].set_yticklabels([])\n",
    "    ax[4].hist(np.ravel(diff_after.data), bins=50)\n",
    "    ax[4].set_xlabel('Difference [m]')\n",
    "    ax[4].set_ylabel('Counts')\n",
    "\n",
    "    # Subtract the median difference over stable surfaces\n",
    "    diff_after_adj = diff_after - med_after_ss\n",
    "    # calculate differences over stable surfaces\n",
    "    ss_mask = ss_mask.reproject(diff_after_adj)\n",
    "    diff_after_adj_ss = diff_after_adj[ss_mask]\n",
    "    med_after_adj_ss, nmad_after_adj_ss = np.median(diff_after_adj_ss), xdem.spatialstats.nmad(diff_after_adj_ss)\n",
    "    # plot\n",
    "    diff_after_adj.plot(cmap=\"coolwarm_r\", vmin=vmin, vmax=vmax, ax=ax[2])\n",
    "    ax[2].set_title(f'Difference after coreg. and \\nremoving median SS difference'\n",
    "                    f'\\nSS median = {np.round(med_after_adj_ss,3)}, SS NMAD = {np.round(med_after_adj_ss, 3)}')\n",
    "    ax[2].set_yticklabels([])\n",
    "    ax[5].hist(np.ravel(diff_after_adj.data), bins=50)\n",
    "    ax[5].set_xlabel('Difference [m]')\n",
    "    ax[5].set_ylabel('Counts')\n",
    "\n",
    "    ax[3].remove()\n",
    "    fig.subplots_adjust(wspace=0.2)\n",
    "    plt.show()\n",
    "\n",
    "    return diff_after, diff_after_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b47fe17-a5d1-4c2e-ba7f-ae5b2068c077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load reference DEM\n",
    "ref_dem = xdem.DEM(gu.Raster(refdem_fn, load_data=True, bands=1))\n",
    "# refdem.set_nodata(0, update_mask=False, update_array=False)\n",
    "\n",
    "# Load source DEM\n",
    "tba_dem = xdem.DEM(gu.Raster(sourcedem_fn, load_data=True, bands=1))\n",
    "# tba_dem.set_nodata(0, update_mask=False, update_array=False)\n",
    "\n",
    "# Reproject to the reference DEM coordinates, etc.\n",
    "tba_dem = tba_dem.reproject(ref_dem)\n",
    "\n",
    "# Load stable surface mask\n",
    "tba_ss_fn = [x for x in ss_fns if os.path.basename(fn)[0:8] in os.path.basename(x)][0]\n",
    "tba_ss = gu.Raster(tba_ss_fn, load_data=True)\n",
    "\n",
    "# Reproject source DEM to reference DEM coords\n",
    "tba_ss = tba_ss.reproject(ref_ss, nodata=0)\n",
    "\n",
    "# Combine masks\n",
    "combined_mask_array = (ref_ss.data == 1) & (tba_ss.data == 1)\n",
    "combined_mask = gu.Mask.from_array(combined_mask_array, \n",
    "                                   transform=ref_ss.transform, \n",
    "                                   crs=ref_ss.crs,\n",
    "                                   nodata=0)\n",
    "combined_mask.set_nodata(0)\n",
    "\n",
    "# -----Apply Nuth and Kaab registration\n",
    "print('\\nNuth and Kaab coregistration...')\n",
    "coreg_obj = xdem.coreg.NuthKaab()\n",
    "diff_nk, diff_adj_nk = coregister(coreg_obj, ref_dem, tba_dem, combined_mask)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc04b71-e473-4955-99f5-6f5dc2acc1f0",
   "metadata": {},
   "source": [
    "## Calculate snow depth: $h_{snow} = h_{source} - h_{ref}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4684de9-4fbc-4ade-9e0f-a838326aa238",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snow-dems",
   "language": "python",
   "name": "snow-dems"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
