{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cce82d3-7031-411a-8300-dba5d94dfc50",
   "metadata": {},
   "source": [
    "# Pipeline for generating snow depth maps from a source DEM and a reference DEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271825c1-e1c9-4e3a-8025-b1b18d09512d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import geedim as gd\n",
    "import ee\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import rioxarray as rxr\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import xdem\n",
    "import geoutils as gu\n",
    "import pyproj\n",
    "from scipy.stats import median_abs_deviation as MAD\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1068a2c3-e25b-4077-bf82-11cb520a396e",
   "metadata": {},
   "source": [
    "## Define paths to DEMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55086c0-d6ea-4d68-b081-562b6829d6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define site name and source DEM date for convenience\n",
    "site_name = 'MCS'\n",
    "sourcedem_date = '20240420'\n",
    "data_path = f'/Users/rdcrlrka/Research/PhD/SkySat-Stereo/study-sites/{site_name}/'\n",
    "refdem_fn = os.path.join(data_path, 'refdem', 'MCS_REFDEM_WGS84.tif')\n",
    "sourcedem_fn = glob.glob(os.path.join(data_path, sourcedem_date, '*DEM_masked.tif'))[0]\n",
    "\n",
    "# Define path for output snow depth images\n",
    "out_dir = f'/Users/rdcrlrka/Research/PhD/SkySat-Stereo/snow_depth_maps/'\n",
    "\n",
    "# Check that files exist\n",
    "# if not os.path.exists(refdem_fn):\n",
    "#     print('Reference DEM not found, check path to file before continuing.')\n",
    "if not os.path.exists(sourcedem_fn):\n",
    "    print('Source DEM not found, check path to file before continuing.')\n",
    "if not os.path.exists(out_dir):\n",
    "    os.mkdir(out_dir)\n",
    "    print('Created directory for output files:', out_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a456e06c-2168-409f-8457-4ffa6ab5d90f",
   "metadata": {},
   "source": [
    "## Construct stable surface mask for source DEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcd5af4-f1ce-4a1a-b0d6-8dab076dee7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_wgs_to_utm(lon: float, lat: float):\n",
    "    \"\"\"\n",
    "    Return best UTM EPSG code based on WGS84 lat and lon coordinate pair. \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    lon: float\n",
    "        longitude coordinate\n",
    "    lat: float\n",
    "        latitude coordinate\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    epsg_code: str\n",
    "        optimal UTM zone, e.g. \"EPSG:32606\"\n",
    "    \"\"\"\n",
    "    utm_band = str((math.floor((lon + 180) / 6) % 60) + 1)\n",
    "    if len(utm_band) == 1:\n",
    "        utm_band = '0' + utm_band\n",
    "    if lat >= 0:\n",
    "        epsg_code = 'EPSG:326' + utm_band\n",
    "        return epsg_code\n",
    "    epsg_code = 'EPSG:327' + utm_band\n",
    "    \n",
    "    return epsg_code\n",
    "\n",
    "def query_gee_for_image(dem_fn, dem_date, site_name, out_dir):\n",
    "    \"\"\"\n",
    "    Query Google Earth Engine for Landsat 8 and 9 surface reflectance (SR), Sentinel-2 top of atmosphere (TOA) or SR imagery.\n",
    "    Images captured within the hour will be mosaicked. For each image, run the classification and snowline detection workflow.\n",
    "\n",
    "    Parameters\n",
    "    __________\n",
    "    dem_bounds: list, numpy.array\n",
    "        bounds of the DEM used for querying and clipping imagery (format = [xmin, ymin, xmax, ymax])\n",
    "    date_date: str\n",
    "        date of the DEM (format = 'YYYYMMDD')\n",
    "    out_dir: str\n",
    "        path in directory where image will be saved\n",
    "\n",
    "    Returns\n",
    "    __________\n",
    "    im_xr: xarray.Dataset\n",
    "        resulting image\n",
    "    \"\"\"\n",
    "\n",
    "    # -----Authenticate and initialize GEE\n",
    "    try:\n",
    "        ee.Initialize()\n",
    "    except:\n",
    "        ee.Authenticate()\n",
    "        ee.Initialize()\n",
    "    \n",
    "    # -----Load DEM\n",
    "    dem = xr.open_dataset(dem_fn)\n",
    "    # Grab lat lon image bounds\n",
    "    dem_bounds = dem.rio.reproject('EPSG:4326').rio.bounds()\n",
    "    \n",
    "    # -----Estimate best UTM zone\n",
    "    centroid_lon = (dem_bounds[0] + dem_bounds[2]) / 2\n",
    "    centroid_lat = (dem_bounds[1] + dem_bounds[3]) / 2\n",
    "    crs = convert_wgs_to_utm(centroid_lon, centroid_lat)\n",
    "    print(f'Best UTM zone = {crs}')\n",
    "    \n",
    "    # -----Reformat image bounds for image querying and clipping\n",
    "    region = {'type': 'Polygon',\n",
    "              'coordinates': [[[dem_bounds[0], dem_bounds[1]],\n",
    "                              [dem_bounds[2], dem_bounds[1]],\n",
    "                              [dem_bounds[2], dem_bounds[3]],\n",
    "                              [dem_bounds[0], dem_bounds[3]],\n",
    "                              [dem_bounds[0], dem_bounds[1]]\n",
    "                             ]]\n",
    "             }\n",
    "\n",
    "    # -----Define the start and end dates for query (within two weeks of DEM date)\n",
    "    if '-' in dem_date:\n",
    "        dem_date = dem_date.replace('-','')\n",
    "    dem_dt = np.datetime64(f'{dem_date[0:4]}-{dem_date[4:6]}-{dem_date[6:8]}')\n",
    "    start_date = str(dem_dt - np.timedelta64(2, 'W'))\n",
    "    end_date = str(dem_dt + np.timedelta64(2, 'W'))\n",
    "\n",
    "    # -----Query GEE for imagery\n",
    "    im_col = gd.MaskedCollection.from_name('COPERNICUS/S2_SR_HARMONIZED').search(start_date=start_date,\n",
    "                                                                                 end_date=end_date,\n",
    "                                                                                 region=region,\n",
    "                                                                                 mask=True,\n",
    "                                                                                 fill_portion=70)\n",
    "    im_col_ids = np.array(im_col.ee_collection.aggregate_array('system:id').getInfo())\n",
    "    def sts_to_date(sts):\n",
    "        return ee.Date(sts).format('yyyy-MM-dd')\n",
    "    im_col_dts = np.array(im_col.ee_collection.aggregate_array('system:time_start').map(sts_to_date).getInfo(), dtype='datetime64[D]')\n",
    "\n",
    "    # -----Download the closest image in time\n",
    "    # Identify ID of the closest image in time\n",
    "    dt_diffs = dem_dt - im_col_dts\n",
    "    Iclosest = np.ravel(np.argwhere(dt_diffs==np.min(dt_diffs)))[0]\n",
    "    im_id = im_col_ids[Iclosest] \n",
    "    im_dt = im_col_dts[Iclosest] \n",
    "    print(f'Closest image date = {im_dt}')\n",
    "    # Create new masked image from ID\n",
    "    im = gd.MaskedImage.from_id(im_id, mask=True, region=region)\n",
    "    # Download to file\n",
    "    out_fn = os.path.join(os.path.dirname(out_dir), f\"{site_name}_{str(im_dt).replace('-','')}_S2_SR_HARMONIZED.tif\")\n",
    "    refl_bands = im.refl_bands\n",
    "    if not os.path.exists(out_fn):\n",
    "        im.download(out_fn, region=region, scale=10, crs=crs, bands=refl_bands, dtype='int16')\n",
    "        print('Sentinel-2 image saved to file:', out_fn)\n",
    "    else:\n",
    "        print('Sentinel-2 image file already exists in directory, loading...')\n",
    "\n",
    "    # -----Open image and restructure data variables\n",
    "    im_xr = xr.open_dataset(out_fn)\n",
    "    band_data = im_xr['band_data']\n",
    "    im_xr_adj = xr.Dataset()\n",
    "    for i, band_name in enumerate(refl_bands):\n",
    "        im_xr_adj[band_name] = band_data.isel(band=i)\n",
    "    im_xr_adj.attrs = im_xr.attrs\n",
    "    for coord in im_xr.coords:\n",
    "        im_xr_adj[coord] = im_xr[coord]\n",
    "    im_xr_adj = im_xr_adj / 1e4 # account for reflectance scalar\n",
    "    \n",
    "    return im_xr_adj, crs\n",
    "\n",
    "def create_stable_surface_mask(im_xr, dem_date, out_fn, crs, plot=True):\n",
    "    \"\"\"\n",
    "    Create stable surface mask by applying an NDSI threshold of 0.35 to the input Sentinel-2 SR image\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    im_xr: xarray.Dataset\n",
    "        input Sentinel-2 SR image\n",
    "    dem_date: str\n",
    "        observation date of DEM\n",
    "    out_fn: str\n",
    "        file name of output stable surfaces file\n",
    "    crs: str\n",
    "        coordinate reference system of output file (e.g., \"EPSG:4326\")\n",
    "    plot: bool\n",
    "        whether to plot results\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    stable_surfaces: xarray.DataArray\n",
    "        resulting stable surfaces mask\n",
    "    \n",
    "    \"\"\"\n",
    "    # Add NDSI band\n",
    "    im_xr['NDSI'] = (im_xr['B3'] - im_xr['B11']) / (im_xr['B3'] + im_xr['B11'])\n",
    "    \n",
    "    # Threshold\n",
    "    ss_xr = xr.where(im_xr['NDSI'] <= 0.4, 1, 0)\n",
    "\n",
    "    # Calculate statistics\n",
    "    num_pixels = len(np.ravel(ss_xr.data))\n",
    "    num_pixels_stable = len(np.argwhere(np.ravel(ss_xr.data)==1))\n",
    "    res_m2 = (ss_xr.x.data[1] - ss_xr.x.data[0]) **2\n",
    "    perc_stable = num_pixels_stable / num_pixels * 100\n",
    "    area_stable_km2 = num_pixels_stable * res_m2 / 1e6\n",
    "    print(f'Stable surfaces = {np.round(perc_stable,2)} % of image, {np.round(area_stable_m2, 2)} km2')\n",
    "\n",
    "    # Write CRS to image\n",
    "    ss_xr = ss_xr.rio.write_crs(crs)\n",
    "    \n",
    "    # Save to file\n",
    "    ss_xr.rio.to_raster(out_fn)\n",
    "    print('Stable surfaces mask saved to file:', out_fn)\n",
    "\n",
    "    ss_xr = rxr.open_rasterio(out_fn)\n",
    "    \n",
    "    # Plot\n",
    "    if plot:\n",
    "        fig, ax = plt.subplots(1, 3, figsize=(12,6))\n",
    "        ax[0].imshow(np.dstack([im_xr.B4.data, im_xr.B3.data, im_xr.B2.data]),\n",
    "                     extent=(np.min(im_xr.x.data), np.max(im_xr.x.data), np.min(im_xr.y.data), np.max(im_xr.y.data)))\n",
    "        ax[0].set_title('Raw image')\n",
    "        ax[1].imshow(im_xr.NDSI.data, clim=(-1,1), cmap='Blues',\n",
    "                     extent=(np.min(im_xr.x.data), np.max(im_xr.x.data), np.min(im_xr.y.data), np.max(im_xr.y.data)))\n",
    "        ax[1].set_title('NDSI')\n",
    "        ax[2].imshow(ss_xr.data[0], clim=(0,1), cmap='Greys',\n",
    "                     extent=(np.min(ss_xr.x.data), np.max(ss_xr.x.data), np.min(ss_xr.y.data), np.max(ss_xr.y.data)))\n",
    "        ax[2].set_title('Stable surfaces')\n",
    "        plt.show()\n",
    "        # save figure\n",
    "        fig_fn = os.path.splitext(out_fn)[0] + '.png'\n",
    "        fig.savefig(fig_fn, dpi=250, bbox_inches='tight')\n",
    "        print('Figure saved to file:', fig_fn)\n",
    "\n",
    "    return ss_xr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262de4f9-3db2-425c-98cb-796906c3140f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if stable surfaces mask already exists in file\n",
    "ss_fn = os.path.join(out_dir, os.path.splitext(os.path.basename(sourcedem_fn))[0] + '_stable_surfaces_mask.tif')\n",
    "if os.path.exists(ss_fn):\n",
    "    print('Stable surfaces mask already exists for DEM')\n",
    "    ss_xr = rxr.open_rasterio(ss_fn)\n",
    "\n",
    "else:\n",
    "    # Query GEE for closest Sentinel-2 image in time\n",
    "    im_xr, crs = query_gee_for_image(sourcedem_fn, sourcedem_date, site_name, out_dir)\n",
    "    \n",
    "    # Create stable surfaces mask\n",
    "    ss_xr = create_stable_surface_mask(im_xr, sourcedem_date, ss_fn, crs=crs, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc19a93-278d-426c-896e-aa21f935bebf",
   "metadata": {},
   "source": [
    "## Coregister source DEM to reference DEM grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5537bd-2783-4634-bf4e-df97ddf9cbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_coreg_object(coreg_name):\n",
    "    if type(coreg_name) == list:\n",
    "        try:\n",
    "            coreg_class = getattr(xdem.coreg.CoregPipeline, coreg_name)\n",
    "            return coreg_class()\n",
    "        except AttributeError:\n",
    "            raise ValueError(f\"Coregistration method '{coreg_name}' not found.\")\n",
    "    elif type(coreg_name) == str:\n",
    "        try:\n",
    "            coreg_class = getattr(xdem.coreg, coreg_name)\n",
    "            return coreg_class()\n",
    "        except AttributeError:\n",
    "            raise ValueError(f\"Coregistration method '{coreg_name}' not found.\")\n",
    "    else:\n",
    "        print('coreg_method format not recognized, exiting...')\n",
    "        return None\n",
    "\n",
    "def coregister_difference(ref_dem_fn=None, source_dem_fn=None, ss_mask_fn=None, coreg_method='NuthKaab'):\n",
    "    # Load DEMs and stable surface mask\n",
    "    ref_dem = xdem.DEM(gu.Raster(ref_dem_fn, load_data=True, bands=1))\n",
    "    tba_dem = xdem.DEM(gu.Raster(source_dem_fn, load_data=True, bands=1))\n",
    "    ss_mask = gu.Raster(ss_mask_fn, load_data=True)\n",
    "    ss_mask = (ss_mask == 0)  # Convert to boolean mask\n",
    "\n",
    "    # Reproject source DEM and stable surface mask to reference DEM grid\n",
    "    tba_dem = tba_dem.reproject(ref_dem)\n",
    "    ss_mask = ss_mask.reproject(ref_dem, nodata=0)\n",
    "\n",
    "    # Set up the coregistration object\n",
    "    coreg_obj = create_coreg_object(coreg_method)\n",
    "    if not coreg_obj:\n",
    "        return None\n",
    "    \n",
    "    # Calculate differences before coregistration\n",
    "    diff_before = tba_dem - ref_dem\n",
    "    # Stable surface stats\n",
    "    diff_before_ss = diff_before.copy()\n",
    "    diff_before_ss.mask = np.logical_and(diff_before.data.mask, ss_mask.data.mask)\n",
    "    diff_before_ss_median = np.nanmedian(diff_before_ss)\n",
    "    diff_before_ss_nmad = xdem.spatialstats.nmad(diff_before_ss)\n",
    "    \n",
    "    # Fit the coregistration object\n",
    "    coreg_obj.fit(ref_dem, tba_dem)    \n",
    "    aligned_dem = coreg_obj.apply(tba_dem)\n",
    "    \n",
    "    # Calculate differences after coregistration\n",
    "    diff_after = aligned_dem - ref_dem\n",
    "    # Stable surface stats\n",
    "    diff_after_ss = diff_after.copy()\n",
    "    diff_after_ss.mask = np.logical_and(diff_after.data.mask, ss_mask.data.mask)\n",
    "    diff_after_ss_median = np.nanmedian(diff_after_ss)\n",
    "    diff_after_ss_nmad = xdem.spatialstats.nmad(diff_after_ss)\n",
    "\n",
    "    # Subtract the median difference over stable surfaces\n",
    "    diff_after_adj = diff_after - ref_dem\n",
    "    # Stable surface stats\n",
    "    diff_after_adj_ss = diff_after_adj.copy()\n",
    "    diff_after_adj_ss.mask = np.logical_and(diff_after_adj.data.mask, ss_mask.data.mask)\n",
    "    diff_after_adj_ss_median = np.nanmedian(diff_after_adj_ss)\n",
    "    diff_after_adj_ss_nmad = xdem.spatialstats.nmad(diff_after_adj_ss)\n",
    "    \n",
    "    # Plotting\n",
    "    fig, ax = plt.subplots(3, 2, figsize=(12,16))\n",
    "    ax = ax.flatten()\n",
    "    # Determine color limits\n",
    "    vmin = np.nanmin([diff_before.data.min(), diff_after.data.min(), diff_after_adj.data.min()])\n",
    "    vmax = np.nanmax([diff_before.data.max(), diff_after.data.max(), diff_after_adj.data.max()])\n",
    "    vmax_abs = np.nanmax([np.abs(vmin), np.abs(vmax)])  # Determine max absolute value to center color at 0\n",
    "    vmin, vmax = -vmax_abs, vmax_abs\n",
    "    # Differences before coregistration\n",
    "    diff_before.plot(cmap=\"coolwarm_r\", vmin=vmin, vmax=vmax, ax=ax[0])\n",
    "    ax[0].set_title(f'Difference before coreg. \\nSS median = {np.round(diff_before_ss_median, 3)}, SS NMAD = {np.round(diff_before_ss_nmad, 3)}')\n",
    "    ax[1].hist(diff_before.data, bins=50)\n",
    "    # Differences after coregistration\n",
    "    diff_after.plot(cmap=\"coolwarm_r\", vmin=vmin, vmax=vmax, ax=ax[2])\n",
    "    ax[2].set_title(f'Difference after coreg. \\nSS median = {np.round(diff_after_ss_median, 3)}, SS NMAD = {np.round(diff_after_ss_nmad, 3)}')\n",
    "    ax[3].hist(diff_after.data, bins=50)\n",
    "    ax[3].set_xlabel('Difference [m]')\n",
    "    ax[3].set_ylabel('Counts')\n",
    "    # Differences after coregistration - median SS difference\n",
    "    diff_after_adj.plot(cmap=\"coolwarm_r\", vmin=vmin, vmax=vmax, ax=ax[4])\n",
    "    ax[4].set_title(f'Difference after coreg. and \\nremoving median SS difference\\nSS median = {np.round(diff_after_adj_ss_median, 3)}, SS NMAD = {np.round(diff_after_adj_ss_nmad, 3)}')\n",
    "    ax[5].hist(diff_after_adj.data, bins=50)\n",
    "    ax[5].set_xlabel('Difference [m]')\n",
    "    ax[5].set_ylabel('Counts')\n",
    "    # Adjust map units to km\n",
    "    for axis in [ax[0], ax[2], ax[4]]:\n",
    "        axis.set_xticks(axis.get_xticks())\n",
    "        axis.set_xticklabels(np.divide(axis.get_xticks(), 1e3).astype(str))\n",
    "        axis.set_yticks(axis.get_yticks())\n",
    "        axis.set_yticklabels(np.divide(axis.get_yticks(), 1e3).astype(str))\n",
    "        axis.set_xlabel('Easting [km]')\n",
    "        axis.set_ylabel('Northing [km]')\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return diff_after, diff_after_adj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b47fe17-a5d1-4c2e-ba7f-ae5b2068c077",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# -----Coregister source DEM and reference DEM\n",
    "diff, diff_adj = coregister_difference(ref_dem_fn=refdem_fn, \n",
    "                                       source_dem_fn=sourcedem_fn, \n",
    "                                       ss_mask_fn=ss_fn, \n",
    "                                       coreg_method='NuthKaab')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e660c192-7440-4f88-8934-5841a9fb1052",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff.plot(vmin=-10, vmax=10, cmap='coolwarm_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd305a4-4b9b-4f05-8340-83d332cd3b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_adj.plot(vmin=-10, vmax=10, cmap='coolwarm_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9678f43-64be-4990-b1f4-f7abec2f0848",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b0d29f-c04e-4dac-a1ba-b34bbf466160",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_dem = xdem.DEM(gu.Raster(refdem_fn, load_data=True, bands=1))\n",
    "tba_dem = xdem.DEM(gu.Raster(sourcedem_fn, load_data=True, bands=1))\n",
    "ss_mask = gu.Raster(ss_fn, load_data=True)\n",
    "ss_mask = (ss_mask == 0)  # Convert to boolean mask\n",
    "\n",
    "# Reproject source DEM and stable surface mask to reference DEM grid\n",
    "tba_dem = tba_dem.reproject(ref_dem)\n",
    "ss_mask = ss_mask.reproject(ref_dem, nodata=0)\n",
    "\n",
    "# Set up the coregistration object\n",
    "coreg_obj = create_coreg_object(\"NuthKaab\")\n",
    "\n",
    "# Calculate differences before coregistration\n",
    "# diff_before = tba_dem - ref_dem\n",
    "# # Stable surface stats\n",
    "# diff_before_ss = diff_before.copy()\n",
    "# diff_before_ss.mask = np.logical_and(diff_before.data.mask, ss_mask.data.mask)\n",
    "# diff_before_ss_median = np.nanmedian(diff_before_ss)\n",
    "# diff_before_ss_nmad = xdem.spatialstats.nmad(diff_before_ss)\n",
    "\n",
    "# Apply coregistration\n",
    "coreg_obj.fit(ref_dem, tba_dem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cfef84-3596-4a36-a81a-2357e1942f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "coreg_obj.meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041534b6-ddb2-403c-9899-fb4c46240976",
   "metadata": {},
   "outputs": [],
   "source": [
    "tba_dem.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d56fa05-6a67-4adb-bf24-b68c6ef9efce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snow-dems",
   "language": "python",
   "name": "snow-dems"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
