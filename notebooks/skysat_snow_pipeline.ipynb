{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3171e89d-d7b8-498c-8e2a-3512418e69e6",
   "metadata": {},
   "source": [
    "# SkySat-snow pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fcef54",
   "metadata": {},
   "source": [
    "## Define settings and paths in directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a95d54-3dcf-4c4c-8d8f-002c37cbd937",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Define paths in directory\n",
    "site_name = \"JacksonCreek\"\n",
    "date = \"20240420\"\n",
    "code_dir = '/Users/raineyaberle/Research/PhD/SnowDEMs/skysat-snow'\n",
    "\n",
    "ref_dem_fn = f'/Volumes/LaCie/raineyaberle/Research/PhD/Skysat-Stereo/study-sites/{site_name}/refdem/USGS_LPC_ID_FEMAHQ_2018_D18_merged_filtered.tif'\n",
    "dem_fn = f'/Volumes/LaCie/raineyaberle/Research/PhD/Skysat-Stereo/study-sites/{site_name}/{date}/{site_name}_{date}_DEM.tif'\n",
    "multispec_dir = f'/Volumes/LaCie/raineyaberle/Research/PhD/SkySat-Stereo/study-sites/{site_name}/{date}/{site_name}_{date}_4band_mosaic.tif'\n",
    "\n",
    "# gcp_fn = f'/Volumes/LaCie/raineyaberle/Research/PhD/Skysat-Stereo/ITD_Functional_Class/ITD_HWY_21.shp'\n",
    "# gcp_elev = 0\n",
    "gcp_fn = f'/Volumes/LaCie/raineyaberle/Research/PhD/Skysat-Stereo/study-sites/JacksonCreek/snotel/JacksonCreek_snotel_site_info.gpkg'\n",
    "gcp_elev = 1.448\n",
    "\n",
    "out_dir = f'/Volumes/LaCie/raineyaberle/Research/PhD/Skysat-Stereo/study-sites/{site_name}/{date}'\n",
    "res = 2 # spatial resolution of outputs [m]\n",
    "gcp_buffer = 3 # buffer for GCP geospatial file [m]\n",
    "\n",
    "# Check that input files and directories exist\n",
    "if not os.path.exists(ref_dem_fn):\n",
    "    print('Reference DEM file not found, please correct ref_dem_fn before continuing.')\n",
    "if not os.path.exists(dem_fn):\n",
    "    print('Input DEM file not found, please correct pc_fn before continuing.')\n",
    "if not os.path.exists(gcp_fn):\n",
    "    print('GCP geospatial file not found, please correct roads_fn before continuing.')\n",
    "if not os.path.exists(multispec_dir):\n",
    "    print('Multispectral images folder not found, please correct multispec_dir before continuing.')\n",
    "out_dir = os.path.join(out_dir, 'skysat_snow')\n",
    "if not os.path.exists(out_dir):\n",
    "    os.mkdir(out_dir)\n",
    "    print('Made directory for outputs:', out_dir)\n",
    "\n",
    "# Make results directories\n",
    "preprocess_dir = os.path.join(out_dir, 'preprocess')\n",
    "masks_dir = os.path.join(out_dir, 'land_cover_masks')\n",
    "corr_coreg_diff_dir = os.path.join(out_dir, 'corr_coreg_diff')\n",
    "for folder in [preprocess_dir, masks_dir, corr_coreg_diff_dir]:\n",
    "    if not os.path.exists(folder):\n",
    "        os.mkdir(folder)\n",
    "\n",
    "# Add path to pipeline utilities\n",
    "sys.path.append(os.path.join(code_dir, 'scripts'))\n",
    "import pipeline_utils as f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a572de4",
   "metadata": {},
   "source": [
    "## Run pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6a1757",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 1. PREPROCESS INPUT FILES #####\n",
    "print('\\n1. PREPROCESS THE INPUT FILES')\n",
    "# Mosaic 4-band SR imagery, preprocess roads and reference DEM\n",
    "multispec_mosaic_fn, gcp_adj_fn, ref_dem_adj_fn = f.preprocess_multispec_refdem_gcp(multispec_dir, ref_dem_fn, gcp_fn, \n",
    "                                                                                    gcp_buffer, preprocess_dir)\n",
    "\n",
    "\n",
    "##### 2. CONSTRUCT LAND COVER MASKS #####\n",
    "print('\\n2. CONSTRUCT LAND COVER MASKS')\n",
    "multispec_mosaic_fn, trees_mask_fn, snow_mask_fn, gcp_mask_fn, ss_mask_fn = f.construct_land_cover_masks(multispec_mosaic_fn, \n",
    "                                                                                                         gcp_adj_fn, masks_dir, \n",
    "                                                                                                         gcp_buffer,\n",
    "                                                                                                         ndvi_threshold=0.1,\n",
    "                                                                                                         ndsi_threshold=0.0)\n",
    "\n",
    "\n",
    "##### 3. CORRECT, COREGISTER, AND DIFFERENCE DEM #####\n",
    "print('\\n3. CORRECT, COREGISTER, AND DIFFERENCE DEM')\n",
    "final_dem_fn, final_ddem_fn = f.correct_coregister_difference(dem_fn, ref_dem_fn, ss_mask_fn, trees_mask_fn, gcp_mask_fn, \n",
    "                                                              gcp_elev, corr_coreg_diff_dir, mask_trees=False, plot_results=True)\n",
    "\n",
    "\n",
    "##### 4. PLOT FINAL DEM AND dDEM #####\n",
    "print('\\n4. PLOT THE FINAL DEM AND dDEM')\n",
    "f.plot_dem_ddem(final_dem_fn, final_ddem_fn, gcp_mask_fn, os.path.join(out_dir, 'final_dem_ddem.png'), vmin=-5, vmax=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4030a225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Estimate the appropriate length scale for calculating slope and aspect\n",
    "# import skgstat as skg\n",
    "# import xdem\n",
    "# import numpy as np\n",
    "# from scipy.optimize import minimize\n",
    "# from skgstat.util.likelihood import get_likelihood\n",
    "\n",
    "# refdem = xdem.DEM(ref_dem_fn)\n",
    "# refdem.set_nodata(np.nan)\n",
    "# x = np.ravel(refdem.coords()[0])\n",
    "# y = np.ravel(refdem.coords()[1])\n",
    "# values = np.ravel(refdem.data)\n",
    "# # remove no data vaalues\n",
    "# ireal = np.argwhere(~np.isnan(values))\n",
    "# x, y, values = x[ireal].ravel(), y[ireal].ravel(), values[ireal].ravel()\n",
    "# coords = np.concatenate([x.reshape(-1,1), y.reshape(-1,1)], axis=1)\n",
    "# # select a subsample to decrease data storage needed\n",
    "# n = 10000\n",
    "# coords, values = coords[0:n, :], values[0:n]\n",
    "\n",
    "# # Calculate the experimental variogram\n",
    "# print('Calculating variogram')\n",
    "# V = skg.Variogram(coords, values, normalize=False, n_lags=25, use_nugget=True)\n",
    "\n",
    "# # Maximum Likehood fit\n",
    "# # base initial guess on separating distance and sample variance\n",
    "# sep_mean = np.nanmean(V.distance)\n",
    "# sam_var = np.nanvar(V.values)\n",
    "# print(f\"Mean sep. distance:  {sep_mean.round(1)}    sample variance: {sam_var.round(1)}\")\n",
    "# # create initial guess\n",
    "# #    mean dist.  variance    5% of variance\n",
    "# p0 = np.array([sep_mean, sam_var, 0.1 * sam_var])\n",
    "# print('initial guess: ', p0.round(1))\n",
    "# # create the bounds to restrict optimization\n",
    "# bounds = [[0, V.bins[-1]], [0, 3*sam_var], [0, 2.9*sam_var]]\n",
    "# print('bounds:        ', bounds)\n",
    "# # load the likelihood function for this variogram\n",
    "# likelihood = get_likelihood(V)\n",
    "# # minimize the likelihood function\n",
    "# res = minimize(likelihood, p0, bounds=bounds, method='SLSQP')\n",
    "# # use 100 steps\n",
    "# x = np.linspace(0, V.bins[-1], 100)\n",
    "# # apply the maximum likelihood fit parameters\n",
    "# y_ml = V.model(x, *res.x)\n",
    "# # apply the trf fit\n",
    "# y_trf = V.fitted_model(x)\n",
    "# # apply Levelberg marquard\n",
    "# V.fit_method = 'lm'\n",
    "# y_lm = V.fitted_model(x)\n",
    "# # apply parameter ml\n",
    "# V.fit_method = 'ml'\n",
    "# y_pml = V.fitted_model(x)\n",
    "\n",
    "# plt.plot(V.bins, V.experimental, '.b', label='experimental')\n",
    "# plt.plot(x, y_trf, '-b', label='SciKit-GStat TRF')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9797640e",
   "metadata": {},
   "source": [
    "## Apply terrain correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc66e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test several terrain variables\n",
    "# terrain_vars = ['elevation', 'slope', 'aspect', 'maximum_curvature']\n",
    "# for terrain_var in terrain_vars:\n",
    "#     print(terrain_var)\n",
    "#     terrain_bias = xdem.coreg.TerrainBias(terrain_var).fit(refdem, dem_after, ss_mask)\n",
    "#     dem_corrected = terrain_bias.apply(dem_after)\n",
    "\n",
    "#     ddem_before = dem_after - refdem\n",
    "#     ddem_after = dem_corrected - refdem\n",
    "\n",
    "#     ddem_before_roads = ddem_before[roads_mask]\n",
    "#     print(f'NMAD before = {np.round(xdem.spatialstats.nmad(ddem_before_roads), 3)} m')\n",
    "\n",
    "#     ddem_after_roads = ddem_after[roads_mask]\n",
    "#     print(f'NMAD after = {np.round(xdem.spatialstats.nmad(ddem_after_roads), 3)} m')\n",
    "#     ddem_after_roads_med = np.nanmedian(ddem_after_roads.data)\n",
    "#     dem_corrected -= ddem_after_roads_med\n",
    "#     ddem_after -= ddem_after_roads_med\n",
    "\n",
    "#     fig, ax = plt.subplots(1, 2, figsize=(12,6))\n",
    "#     ddem_before.plot(cmap='coolwarm_r', vmin=-5, vmax=5, ax=ax[0])\n",
    "#     ax[0].set_title('dDEM')\n",
    "#     ddem_after.plot(cmap='coolwarm_r', vmin=-5, vmax=5, ax=ax[1])\n",
    "#     ax[1].set_title('Corrected dDEM')\n",
    "#     plt.suptitle(terrain_var)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef04653",
   "metadata": {},
   "source": [
    "## Try correcting for directional bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e81070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for angle in np.linspace(0, 360, 5)[0:-1]:\n",
    "#     dir_bias = xdem.coreg.DirectionalBias(angle=angle).fit(refdem, dem_after, ss_mask)\n",
    "#     dem_corrected = dir_bias.apply(dem_after)\n",
    "#     ddem = dem_corrected - refdem\n",
    "#     fig, ax = plt.subplots(1, 1, figsize=(6,6))\n",
    "#     ddem.plot(cmap='coolwarm_r', vmin=-5, vmax=5, ax=ax)\n",
    "#     ax.set_title(angle)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dff346",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skysat_snow_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
