{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1349da4-56a4-430e-9592-eb3fea97209b",
   "metadata": {},
   "source": [
    "# Test using autoRIFT for horizontal coregistration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a07773-db7d-4c55-9454-0143137f7ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from autoRIFT import autoRIFT\n",
    "from geogrid import GeogridOptical\n",
    "import xdem\n",
    "import geoutils as gu\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7165557-d749-4a51-a335-809433e00a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define inputs\n",
    "data_dir = '/Volumes/LaCie/raineyaberle/Research/PhD/SkySat-Stereo/study-sites/MCS'\n",
    "refdem_fn = os.path.join(data_dir, 'refdem', 'MCS_REFDEM_WGS84_CHM.tif')\n",
    "sourcedem_fn = os.path.join(data_dir, '20240420', 'MCS_20240420-1_DEM.tif')\n",
    "ortho_fn = os.path.join(data_dir, '20240420', 'MCS_20240420-1_4band_orthomosaic.tif')\n",
    "\n",
    "job_dir = '/Volumes/LaCie/raineyaberle/Research/PhD/SkySat-Stereo/snow_depth_maps/MCS_20240420-1_ref+chm_sourcetrees'\n",
    "masks_dir = os.path.join(job_dir, 'land_cover_masks')\n",
    "trees_mask_fn = os.path.join(masks_dir, 'trees_mask.tif')\n",
    "roads_mask_fn = os.path.join(masks_dir, 'roads_mask.tif')\n",
    "snow_mask_fn = os.path.join(masks_dir, 'snow_mask.tif')\n",
    "ss_mask_fn = os.path.join(masks_dir, 'stable_surfaces_mask.tif')\n",
    "\n",
    "out_dir = os.path.join(job_dir, 'testing_tree_coreg')\n",
    "if not os.path.exists(out_dir):\n",
    "    os.mkdir(out_dir)\n",
    "    print('Made directory for outputs:', out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2640704-440e-4510-9adc-803eb0a61d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deramp input DEM on stable surfaces\n",
    "vmin, vmax = -10, 10\n",
    "\n",
    "# Define output file names\n",
    "sourcedem_deramped_fn = os.path.join(out_dir, os.path.basename(sourcedem_fn).replace('.tif', '_deramped.tif'))\n",
    "fig_fn = os.path.join(out_dir, os.path.basename(sourcedem_fn).replace('.tif', '_deramp_correction.png'))\n",
    "\n",
    "if not os.path.exists(sourcedem_deramped_fn):\n",
    "    # Load input files\n",
    "    refdem = xdem.DEM(refdem_fn)\n",
    "    sourcedem = xdem.DEM(sourcedem_fn)\n",
    "    sourcedem = sourcedem.reproject(refdem)\n",
    "    ss_mask = gu.Raster(ss_mask_fn, load_data=True)\n",
    "    ss_mask = ss_mask.reproject(ref_dem)\n",
    "    ss_mask = (ss_mask == 1) # convert to boolean mask\n",
    "\n",
    "    # Calculate difference refdem\n",
    "    diff_before = sourcedem - ref_dem\n",
    "\n",
    "    # Fit and apply Deramp object\n",
    "    print('Fitting deramper...')\n",
    "    deramp = xdem.coreg.Deramp(poly_order=2)\n",
    "    deramp.fit(refdem, sourcedem, inlier_mask=ss_mask)\n",
    "    meta = deramp.meta\n",
    "    print(meta)\n",
    "    dem_deramped = deramp.apply(sourcedem)\n",
    "\n",
    "    # Save corrected DEM\n",
    "    sourcedem_deramped.save(sourcedem_deramped_fn)\n",
    "    print('Deramped DEM saved to file:', sourcedem_deramped_fn)\n",
    "\n",
    "    # Calculate difference after\n",
    "    diff_after = sourcedem_deramped - refdem\n",
    "\n",
    "    # Plot results\n",
    "    print('Plotting deramp correction results...')\n",
    "    bins = np.linspace(vmin, vmax, num=100)\n",
    "    fig, ax = plt.subplots(2, 2, figsize=(10,10))\n",
    "    ax = ax.flatten()\n",
    "    diff_before.plot(cmap='coolwarm_r', vmin=vmin, vmax=vmax, ax=ax[0])\n",
    "    ax[0].set_title('dDEM')\n",
    "    diff_after.plot(cmap='coolwarm_r', vmin=vmin, vmax=vmax, ax=ax[1])\n",
    "    ax[1].set_title('Deramped dDEM')\n",
    "    ax[2].hist(np.ravel(diff_before.data), color='grey', bins=bins)\n",
    "    ax[2].set_xlim(vmin,vmax)\n",
    "    ax[2].set_xlabel('Elevation differences (all surfaces) [m]')\n",
    "    ax[3].hist(np.ravel(diff_after.data), color='grey', bins=bins)\n",
    "    ax[3].set_xlim(vmin, vmax)\n",
    "    ax[3].set_xlabel('Elevation differences (all surfaces) [m]')\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Save figure\n",
    "    fig.savefig(fig_fn, dpi=300, bbox_inches='tight')\n",
    "    print('Figure saved to file:', fig_fn)\n",
    "    \n",
    "else:\n",
    "    print('Deramped DEM already exists in file, skipping.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7f61ec-bfb3-40de-b199-30e33dba2314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate hillshade, mask snow-covered pixels, save hillshades to file\n",
    "\n",
    "# Define output files\n",
    "source_hillshade_fn = os.path.join(out_dir, 'source_hillshade_snowfree.tif')\n",
    "ref_hillshade_fn = os.path.join(out_dir, 'ref_hillshade.tif')\n",
    "fig_fn = os.path.join(out_dir, 'hillshade_inputs.png')\n",
    "\n",
    "if not os.path.exists(source_hillshade_fn):\n",
    "\n",
    "    # Load input files\n",
    "    print('Loading input files...')\n",
    "\n",
    "    source_dem = xdem.DEM(sourcedem_deramped_fn)\n",
    "    ref_dem = xdem.DEM(refdem_fn)\n",
    "    snow_mask = gu.Raster(snow_mask_fn, load_data=True)\n",
    "    snow_mask = snow_mask.reproject(ref_dem)\n",
    "    snow_mask = (snow_mask == 1)\n",
    "\n",
    "    # Calculate hillshades\n",
    "    print('Calculating hillshades...')\n",
    "    source_hillshade = source_dem.hillshade()\n",
    "    ref_hillshade = ref_dem.hillshade()\n",
    "\n",
    "    # Mask snow-covered pixels\n",
    "    print('Masking snow-covered pixels in source hillshade...')\n",
    "    new_mask = (source_hillshade.data.mask | snow_mask.data.data==1)\n",
    "    source_hillshade.set_mask(new_mask)\n",
    "    \n",
    "    # Save hillshades to file\n",
    "    source_hillshade.save(source_hillshade_fn)\n",
    "    print('Source hillshade saved to file:', source_hillshade_fn)\n",
    "    ref_hillshade.save(ref_hillshade_fn)\n",
    "    print('Reference hillshade saved to file:', ref_hillshade_fn)\n",
    "    \n",
    "    # Plot hillshades\n",
    "    print('Plotting hillshades...')\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12,5))\n",
    "    ref_hillshade.plot(ax=ax[0], cmap='Greys')\n",
    "    ax[0].set_title('Reference hillshade')\n",
    "    source_hillshade.plot(ax=ax[1], cmap='Greys')\n",
    "    ax[1].set_title('Source hillshade')\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Save figure\n",
    "    fig.savefig(fig_fn, dpi=300, bbox_inches='tight')\n",
    "    print('Figure saved to file:', fig_fn)\n",
    "\n",
    "else:\n",
    "    print('Input hillshades already exist in file, skipping.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa2bf7c-56ba-4e1a-8df4-4fc28d22bd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run autoRIFT on input hillshades\n",
    "\n",
    "# Create autoRIFT object\n",
    "obj = autoRIFT()\n",
    "\n",
    "# Define data inputs and settings\n",
    "I1 = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739b067a-f26d-498b-ae96-88e439c4055f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runAutorift(I1, I2, xGrid, yGrid, Dx0, Dy0, SRx0, SRy0, CSMINx0, CSMINy0, CSMAXx0, CSMAXy0, noDataMask, optflag,\n",
    "                nodata, mpflag, geogrid_run_info=None, preprocessing_methods=('hps', 'hps'),\n",
    "                preprocessing_filter_width=5):\n",
    "    '''\n",
    "    Wire and run geogrid.\n",
    "    '''\n",
    "\n",
    "    from autoRIFT import autoRIFT\n",
    "    import numpy as np\n",
    "    import time\n",
    "    \n",
    "    obj = autoRIFT()\n",
    "\n",
    "    obj.WallisFilterWidth = preprocessing_filter_width\n",
    "    print(f'Setting Wallis Filter Width to {preprocessing_filter_width}')\n",
    "\n",
    "    obj.MultiThread = mpflag\n",
    "\n",
    "    # take the amplitude only for the radar images\n",
    "    if optflag == 0:\n",
    "        I1 = np.abs(I1)\n",
    "        I2 = np.abs(I2)\n",
    "\n",
    "    obj.I1 = I1\n",
    "    obj.I2 = I2\n",
    "\n",
    "    # create the grid if it does not exist\n",
    "    if xGrid is None:\n",
    "        m,n = obj.I1.shape\n",
    "        xGrid = np.arange(obj.SkipSampleX+10,n-obj.SkipSampleX,obj.SkipSampleX)\n",
    "        yGrid = np.arange(obj.SkipSampleY+10,m-obj.SkipSampleY,obj.SkipSampleY)\n",
    "        nd = xGrid.__len__()\n",
    "        md = yGrid.__len__()\n",
    "        obj.xGrid = np.int32(np.dot(np.ones((md,1)),np.reshape(xGrid,(1,xGrid.__len__()))))\n",
    "        obj.yGrid = np.int32(np.dot(np.reshape(yGrid,(yGrid.__len__(),1)),np.ones((1,nd))))\n",
    "        noDataMask = np.logical_not(obj.xGrid)\n",
    "    else:\n",
    "        obj.xGrid = xGrid\n",
    "        obj.yGrid = yGrid\n",
    "\n",
    "    # NOTE: This assumes the zero values in the image are only outside the valid image \"frame\",\n",
    "    #        but is not true for Landsat-7 after the failure of the Scan Line Corrector, May 31, 2003.\n",
    "    #        We should not mask based on zero values in the L7 images as this percolates into SearchLimit{X,Y}\n",
    "    #        and prevents autoRIFT from looking at large parts of the images, but untangling the logic here\n",
    "    #        has proved too difficult, so lets just turn it off if `wallis_fill` preprocessing is going to be used.\n",
    "    # generate the nodata mask where offset searching will be skipped based on 1) imported nodata mask and/or 2) zero values in the image\n",
    "    if 'wallis_fill' not in preprocessing_methods:\n",
    "        for ii in range(obj.xGrid.shape[0]):\n",
    "            for jj in range(obj.xGrid.shape[1]):\n",
    "                if (obj.yGrid[ii,jj] != nodata)&(obj.xGrid[ii,jj] != nodata):\n",
    "                    if (I1[obj.yGrid[ii,jj]-1,obj.xGrid[ii,jj]-1]==0)|(I2[obj.yGrid[ii,jj]-1,obj.xGrid[ii,jj]-1]==0):\n",
    "                        noDataMask[ii,jj] = True\n",
    "\n",
    "    ######### mask out nodata to skip the offset searching using the nodata mask (by setting SearchLimit to be 0)\n",
    "\n",
    "    if SRx0 is None:\n",
    "#        ###########     uncomment to customize SearchLimit based on velocity distribution (i.e. Dx0 must not be None)\n",
    "#        obj.SearchLimitX = np.int32(4+(25-4)/(np.max(np.abs(Dx0[np.logical_not(noDataMask)]))-np.min(np.abs(Dx0[np.logical_not(noDataMask)])))*(np.abs(Dx0)-np.min(np.abs(Dx0[np.logical_not(noDataMask)]))))\n",
    "#        obj.SearchLimitY = 5\n",
    "#        ###########\n",
    "        obj.SearchLimitX = obj.SearchLimitX * np.logical_not(noDataMask)\n",
    "        obj.SearchLimitY = obj.SearchLimitY * np.logical_not(noDataMask)\n",
    "    else:\n",
    "        obj.SearchLimitX = SRx0\n",
    "        obj.SearchLimitY = SRy0\n",
    "#        ############ add buffer to search range\n",
    "#        obj.SearchLimitX[obj.SearchLimitX!=0] = obj.SearchLimitX[obj.SearchLimitX!=0] + 2\n",
    "#        obj.SearchLimitY[obj.SearchLimitY!=0] = obj.SearchLimitY[obj.SearchLimitY!=0] + 2\n",
    "\n",
    "    if CSMINx0 is not None:\n",
    "        obj.ChipSizeMaxX = CSMAXx0\n",
    "        obj.ChipSizeMinX = CSMINx0\n",
    "\n",
    "        if geogrid_run_info is None:\n",
    "            gridspacingx = float(str.split(runCmd('fgrep \"Grid spacing in m:\" testGeogrid.txt'))[-1])\n",
    "            chipsizex0 = float(str.split(runCmd('fgrep \"Smallest Allowable Chip Size in m:\" testGeogrid.txt'))[-1])\n",
    "            try:\n",
    "                pixsizex = float(str.split(runCmd('fgrep \"Ground range pixel size:\" testGeogrid.txt'))[-1])\n",
    "            except:\n",
    "                pixsizex = float(str.split(runCmd('fgrep \"X-direction pixel size:\" testGeogrid.txt'))[-1])\n",
    "        else:\n",
    "            gridspacingx = geogrid_run_info['gridspacingx']\n",
    "            chipsizex0 = geogrid_run_info['chipsizex0']\n",
    "            pixsizex = geogrid_run_info['XPixelSize']\n",
    "\n",
    "        obj.ChipSize0X = int(np.ceil(chipsizex0/pixsizex/4)*4)\n",
    "        obj.GridSpacingX = int(obj.ChipSize0X*gridspacingx/chipsizex0)\n",
    "\n",
    "        # obj.ChipSize0X = np.min(CSMINx0[CSMINx0!=nodata])\n",
    "        RATIO_Y2X = CSMINy0/CSMINx0\n",
    "        obj.ScaleChipSizeY = np.median(RATIO_Y2X[(CSMINx0!=nodata)&(CSMINy0!=nodata)])\n",
    "        # obj.ChipSizeMaxX = obj.ChipSizeMaxX / obj.ChipSizeMaxX * 544\n",
    "        # obj.ChipSizeMinX = obj.ChipSizeMinX / obj.ChipSizeMinX * 68\n",
    "    else:\n",
    "        if ((optflag == 1)&(xGrid is not None)):\n",
    "            obj.ChipSizeMaxX = 32\n",
    "            obj.ChipSizeMinX = 16\n",
    "            obj.ChipSize0X = 16\n",
    "\n",
    "    # create the downstream search offset if not provided as input\n",
    "    if Dx0 is not None:\n",
    "        obj.Dx0 = Dx0\n",
    "        obj.Dy0 = Dy0\n",
    "    else:\n",
    "        obj.Dx0 = obj.Dx0 * np.logical_not(noDataMask)\n",
    "        obj.Dy0 = obj.Dy0 * np.logical_not(noDataMask)\n",
    "\n",
    "    # replace the nodata value with zero\n",
    "    obj.xGrid[noDataMask] = 0\n",
    "    obj.yGrid[noDataMask] = 0\n",
    "    obj.Dx0[noDataMask] = 0\n",
    "    obj.Dy0[noDataMask] = 0\n",
    "    if SRx0 is not None:\n",
    "        obj.SearchLimitX[noDataMask] = 0\n",
    "        obj.SearchLimitY[noDataMask] = 0\n",
    "    if CSMINx0 is not None:\n",
    "        obj.ChipSizeMaxX[noDataMask] = 0\n",
    "        obj.ChipSizeMinX[noDataMask] = 0\n",
    "\n",
    "    # convert azimuth offset to vertical offset as used in autoRIFT convention\n",
    "    if optflag == 0:\n",
    "        obj.Dy0 = -1 * obj.Dy0\n",
    "\n",
    "\n",
    "\n",
    "    ######## preprocessing\n",
    "    t1 = time.time()\n",
    "    print(\"Pre-process Start!!!\")\n",
    "    print(f\"Using Wallis Filter Width: {obj.WallisFilterWidth}\")\n",
    "#    obj.zeroMask = 1\n",
    "\n",
    "    # TODO: Allow different filters to be applied images independently\n",
    "    # default to most stringent filtering\n",
    "    if 'wallis_fill' in preprocessing_methods:\n",
    "        obj.preprocess_filt_wal_nodata_fill()\n",
    "    elif 'wallis' in preprocessing_methods:\n",
    "        obj.preprocess_filt_wal()\n",
    "    elif 'fft' in preprocessing_methods:\n",
    "        # FIXME: The Landsat 4/5 FFT preprocessor looks for the image corners to\n",
    "        #        determine the scene rotation, but Geogrid + autoRIFT rond the\n",
    "        #        corners when co-registering and chop the non-overlapping corners\n",
    "        #        when subsetting to the common image overlap. FFT filer needs to\n",
    "        #        be applied to the native images before they are processed by\n",
    "        #        Geogrid or autoRIFT.\n",
    "        # obj.preprocess_filt_wal()\n",
    "        # obj.preprocess_filt_fft()\n",
    "        warnings.warn('FFT filtering must be done before processing with geogrid! Be careful when using this method', UserWarning)\n",
    "    else:\n",
    "        obj.preprocess_filt_hps()\n",
    "#    obj.I1 = np.abs(I1)\n",
    "#    obj.I2 = np.abs(I2)\n",
    "    print(\"Pre-process Done!!!\")\n",
    "    print(time.time()-t1)\n",
    "\n",
    "    t1 = time.time()\n",
    "#    obj.DataType = 0\n",
    "    obj.uniform_data_type()\n",
    "    print(\"Uniform Data Type Done!!!\")\n",
    "    print(time.time()-t1)\n",
    "\n",
    "#    pdb.set_trace()\n",
    "\n",
    "#    obj.sparseSearchSampleRate = 16\n",
    "\n",
    "    obj.OverSampleRatio = 64\n",
    "#    obj.colfiltChunkSize = 4\n",
    "\n",
    "    #   OverSampleRatio can be assigned as a scalar (such as the above line) or as a Python dictionary below for intellgient use (ChipSize-dependent).\n",
    "    #   Here, four chip sizes are used: ChipSize0X*[1,2,4,8] and four OverSampleRatio are considered [16,32,64,128]. The intelligent selection of OverSampleRatio (as a function of chip size) was determined by analyzing various combinations of (OverSampleRatio and chip size) and comparing the resulting image quality and statistics with the reference scenario (where the largest OverSampleRatio of 128 and chip size of ChipSize0X*8 are considered).\n",
    "    #   The selection for the optical data flag is based on Landsat-8 data over an inland region (thus stable and not moving much) of Greenland, while that for the radar flag (optflag = 0) is based on Sentinel-1 data over the same region of Greenland.\n",
    "    if CSMINx0 is not None:\n",
    "        if (optflag == 1):\n",
    "            obj.OverSampleRatio = {obj.ChipSize0X:16,obj.ChipSize0X*2:32,obj.ChipSize0X*4:64,obj.ChipSize0X*8:64}\n",
    "        else:\n",
    "            obj.OverSampleRatio = {obj.ChipSize0X:32,obj.ChipSize0X*2:64,obj.ChipSize0X*4:128,obj.ChipSize0X*8:128}\n",
    "\n",
    "\n",
    "\n",
    "#    ########## export preprocessed images to files; can be commented out if not debugging\n",
    "#\n",
    "#    t1 = time.time()\n",
    "#\n",
    "#    I1 = obj.I1\n",
    "#    I2 = obj.I2\n",
    "#\n",
    "#    length,width = I1.shape\n",
    "#\n",
    "#    filename1 = 'I1_uint8_hpsnew.off'\n",
    "#\n",
    "#    slcFid = open(filename1, 'wb')\n",
    "#\n",
    "#    for yy in range(length):\n",
    "#        data = I1[yy,:]\n",
    "#        data.astype(np.float32).tofile(slcFid)\n",
    "#\n",
    "#    slcFid.close()\n",
    "#\n",
    "#    img = isceobj.createOffsetImage()\n",
    "#    img.setFilename(filename1)\n",
    "#    img.setBands(1)\n",
    "#    img.setWidth(width)\n",
    "#    img.setLength(length)\n",
    "#    img.setAccessMode('READ')\n",
    "#    img.renderHdr()\n",
    "#\n",
    "#\n",
    "#    filename2 = 'I2_uint8_hpsnew.off'\n",
    "#\n",
    "#    slcFid = open(filename2, 'wb')\n",
    "#\n",
    "#    for yy in range(length):\n",
    "#        data = I2[yy,:]\n",
    "#        data.astype(np.float32).tofile(slcFid)\n",
    "#\n",
    "#    slcFid.close()\n",
    "#\n",
    "#    img = isceobj.createOffsetImage()\n",
    "#    img.setFilename(filename2)\n",
    "#    img.setBands(1)\n",
    "#    img.setWidth(width)\n",
    "#    img.setLength(length)\n",
    "#    img.setAccessMode('READ')\n",
    "#    img.renderHdr()\n",
    "#\n",
    "#    print(\"output Done!!!\")\n",
    "#    print(time.time()-t1)\n",
    "\n",
    "\n",
    "    ########## run Autorift\n",
    "    t1 = time.time()\n",
    "    print(\"AutoRIFT Start!!!\")\n",
    "    obj.runAutorift()\n",
    "    print(\"AutoRIFT Done!!!\")\n",
    "    print(time.time()-t1)\n",
    "\n",
    "    import cv2\n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    noDataMask = cv2.dilate(noDataMask.astype(np.uint8),kernel,iterations = 1)\n",
    "    noDataMask = noDataMask.astype(np.bool)\n",
    "\n",
    "\n",
    "    return obj.Dx, obj.Dy, obj.InterpMask, obj.ChipSizeX, obj.GridSpacingX, obj.ScaleChipSizeY, obj.SearchLimitX, obj.SearchLimitY, obj.origSize, noDataMask\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snow-dems",
   "language": "python",
   "name": "snow-dems"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
